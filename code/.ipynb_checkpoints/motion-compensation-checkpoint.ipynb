{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from os.path import join, isfile, exists, isdir, dirname\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '../sample-data/dataset_synthesize.xlsx'\n",
    "data_dir = '../sample-data'\n",
    "\n",
    "export_dir_prefix = '../outputs/'\n",
    "export_mp4_dir = '../outputs/mp4-outputs'\n",
    "\n",
    "ROI_margin_suffix_list = ['withoutROImargin']  #['withROImargin', 'withoutROImargin']\n",
    "frame_rate_suffix_list = ['fullFrameRate']  #['halfFrameRate', 'fullFrameRate']\n",
    "\n",
    "fixed_size_ROI = False  #if True, the output ROIs will have a fixed size, rather than fitted to the lesion\n",
    "\n",
    "set_quantile = 0.50  #initial quantile\n",
    "threshold_decrease_per_step = 0.02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_data_dir(x, data_dir):\n",
    "    if pd.isna(x):\n",
    "        return None\n",
    "    else:\n",
    "        return join(data_dir, x)\n",
    "\n",
    "\n",
    "\n",
    "def load_pickle(pickle_path):\n",
    "    with open(pickle_path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    print(data.shape)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "def find_ref_frames_from_nifti(nifti_path, ROI_margin_suffix, search_margin):\n",
    "    \n",
    "    nifti_array = np.transpose(nib.load(nifti_path).get_fdata()).astype(int)\n",
    "    print(nifti_array.shape)  # expected (frames, height, width)\n",
    "\n",
    "    spatial_sum = np.sum(nifti_array, axis=(1, 2))  # shape (frames,)\n",
    "    ref_frames = np.argwhere(spatial_sum > 0)\n",
    "    ref_frames = np.reshape(ref_frames, ref_frames.shape[0])\n",
    "\n",
    "    if ROI_margin_suffix == 'withROImargin':\n",
    "        ROI_margin = int(search_margin/2)\n",
    "    elif ROI_margin_suffix == 'withoutROImargin':\n",
    "        ROI_margin = 0\n",
    "    \n",
    "    bboxes = []\n",
    "    masks = []\n",
    "    for i,ref_frame in enumerate(ref_frames):\n",
    "        mask = nifti_array[ref_frame]\n",
    "        pos_coor = np.argwhere(mask > 0)\n",
    "        x_values = pos_coor[:, 1]\n",
    "        y_values = pos_coor[:, 0]\n",
    "        x0 = x_values.min()\n",
    "        x1 = x_values.max()\n",
    "        w = x1 - x0 + 1\n",
    "        y0 = y_values.min()\n",
    "        y1 = y_values.max()\n",
    "        h = y1 - y0 + 1\n",
    "        \n",
    "        bboxes.append((x0-ROI_margin,\n",
    "                       y0-ROI_margin,\n",
    "                       w+(2*ROI_margin),\n",
    "                       h+(2*ROI_margin)))\n",
    "        masks.append(mask[y0-ROI_margin:y0-ROI_margin+h+(2*ROI_margin), \n",
    "                          x0-ROI_margin:x0-ROI_margin+w+(2*ROI_margin)])\n",
    "\n",
    "    return ref_frames, bboxes, masks\n",
    "\n",
    "\n",
    "\n",
    "def export_video(cine_array, mp4_path, CineRate):\n",
    "\n",
    "    mp4_dir = dirname(mp4_path)\n",
    "    if not exists(mp4_dir):\n",
    "        os.makedirs(mp4_dir)\n",
    "\n",
    "    width = cine_array.shape[2]\n",
    "    height = cine_array.shape[1]\n",
    "    if pd.notna(CineRate):\n",
    "        frame_rate = int(CineRate)\n",
    "    else:\n",
    "        print('no CineRate in excel file; using default frame rate = 9')\n",
    "        frame_rate = 9\n",
    "\n",
    "    writer = cv2.VideoWriter(mp4_path, cv2.VideoWriter_fourcc(*'XVID'), frame_rate, (width, height))\n",
    "\n",
    "    if len(cine_array.shape) == 3:  # grayscale\n",
    "        for frame in range(cine_array.shape[0]):\n",
    "            writer.write(cv2.cvtColor(cine_array[frame], cv2.COLOR_GRAY2BGR))\n",
    "    elif len(cine_array.shape) == 4:  # RGB\n",
    "        for frame in range(cine_array.shape[0]):\n",
    "            writer.write(cine_array[frame])\n",
    "    else:\n",
    "        print('color channel not compatible for video exporting; please check dimension of array.')\n",
    "\n",
    "    writer.release()\n",
    "    \n",
    "    \n",
    "    \n",
    "def apply_blur(cine_array):\n",
    "    out = np.zeros(cine_array.shape)\n",
    "    for frame in range(cine_array.shape[0]):\n",
    "        img = cine_array[frame]\n",
    "        img = cv2.GaussianBlur(img, (21, 21), 0)\n",
    "        out[frame] = img\n",
    "    out = out.astype(np.uint8)\n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "def plot_correlation(corr_with_ref, threshold):\n",
    "    plt.figure(figsize=(24,6))\n",
    "    plt.axhline(threshold, color='b')\n",
    "    plt.plot(range(len(corr_with_ref)), corr_with_ref, marker='o', color='g', label='corr_with_ref')\n",
    "    plt.ylim(0,1.0)\n",
    "    plt.ylabel('corr_coef')\n",
    "    plt.xlabel('frame')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "def find_correlation(bmode, ref_bmodes, set_quantile):\n",
    "    \n",
    "    n_refs = len(ref_bmodes)\n",
    "    n_frames = bmode.shape[0]\n",
    "    correlations = np.zeros((n_refs, n_frames))\n",
    "    \n",
    "    for ref_idx in range(n_refs):\n",
    "        ref = ref_bmodes[ref_idx]\n",
    "        for frame in range(n_frames):\n",
    "            similarity_map = cv2.matchTemplate(bmode[frame], ref, cv2.TM_CCOEFF_NORMED)\n",
    "            min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(similarity_map)\n",
    "            correlations[ref_idx, frame] = max_val\n",
    "            \n",
    "    correlations = np.mean(correlations, axis=0)\n",
    "    threshold = np.quantile(correlations, set_quantile)\n",
    "    \n",
    "    return correlations, threshold\n",
    "\n",
    "\n",
    "\n",
    "def check_bbox_move(previous_all_lesion_bboxes, all_lesion_bboxes):\n",
    "    \n",
    "    bbox_move = False\n",
    "    \n",
    "    for frame in range(len(previous_all_lesion_bboxes)):\n",
    "        previous_bbox = previous_all_lesion_bboxes[frame]\n",
    "        current_bbox = all_lesion_bboxes[frame]\n",
    "        if not(previous_bbox is None):\n",
    "            if not(previous_bbox == current_bbox):\n",
    "                bbox_move = True\n",
    "                break\n",
    "    \n",
    "    return bbox_move\n",
    "\n",
    "\n",
    "\n",
    "def compute_similarity_map(search_region, ref_patches, current_ref_idx):\n",
    "    \n",
    "    n_refs = len(ref_patches)\n",
    "    corrs = np.zeros((n_refs,))\n",
    "    \n",
    "    for ref_idx in range(n_refs):\n",
    "        ref = ref_patches[ref_idx]\n",
    "        similarity_map = cv2.matchTemplate(search_region, ref, cv2.TM_CCOEFF_NORMED)\n",
    "        min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(similarity_map)\n",
    "        corrs[ref_idx] = max_val\n",
    "        if current_ref_idx == ref_idx:\n",
    "            current_max_loc = max_loc\n",
    "            \n",
    "    mean_corr = np.mean(corrs)\n",
    "            \n",
    "    return mean_corr, current_max_loc\n",
    "\n",
    "\n",
    "\n",
    "def resize_MC_bboxes(bboxes):\n",
    "    #resize bboxes to minimum width and height\n",
    "    \n",
    "    min_w = min([b[2] for b in bboxes if not(b is None)])\n",
    "    min_h = min([b[3] for b in bboxes if not(b is None)])\n",
    "    \n",
    "    for i in range(len(bboxes)):\n",
    "        if bboxes[i] is None:\n",
    "            continue\n",
    "        x0, y0, w, h = bboxes[i]\n",
    "        new_w = min_w\n",
    "        new_h = min_h\n",
    "        new_x0 = x0 + int((w-new_w)/2)\n",
    "        new_y0 = y0 + int((h-new_h)/2)\n",
    "        bboxes[i] = (new_x0, new_y0, new_w, new_h)\n",
    "        \n",
    "    return bboxes\n",
    "\n",
    "\n",
    "\n",
    "def create_CE_MC_bboxes(bmode_bboxes, x0_bmode, x0_CE, CE_side):\n",
    "    \n",
    "    CE_bboxes = [None] * len(bmode_bboxes)\n",
    "    \n",
    "    for i in range(len(bmode_bboxes)):\n",
    "        if bmode_bboxes[i] is None:\n",
    "            continue\n",
    "        x0, y0, w, h = bmode_bboxes[i]\n",
    "        \n",
    "        if CE_side == 'r':\n",
    "            new_x0 = x0 + (x0_CE-x0_bmode)\n",
    "        elif CE_side == 'l':\n",
    "            new_x0 = x0 - (x0_bmode-x0_CE)\n",
    "        else:\n",
    "            raise Exception('Error in create_CE_MC_bboxes')\n",
    "            \n",
    "        CE_bboxes[i] = (new_x0, y0, w, h)\n",
    "    \n",
    "    return CE_bboxes\n",
    "\n",
    "\n",
    "\n",
    "def create_segmentation_masks(ref_frames, ref_masks, n_frames):\n",
    "    \n",
    "    min_h = min([m.shape[0] for m in ref_masks])\n",
    "    min_w = min([m.shape[1] for m in ref_masks])\n",
    "    \n",
    "    seg_masks = np.zeros((n_frames, min_h, min_w))\n",
    "    \n",
    "    for ref_idx in range(ref_frames.shape[0]):\n",
    "        ref_frame = ref_frames[ref_idx]\n",
    "        \n",
    "        #compute the temporal segment the ref_frame is responsible for\n",
    "        if ref_idx == 0:\n",
    "            if ref_idx == ref_frames.shape[0] - 1:\n",
    "                #There is only 1 ref_frame\n",
    "                ref_begin = 0\n",
    "                ref_end = n_frames\n",
    "            else:\n",
    "                #This is the first ref_frame. There are >1 ref frames.\n",
    "                ref_begin = 0\n",
    "                ref_end = int((ref_frames[ref_idx]+ref_frames[ref_idx+1])/2)\n",
    "        else:\n",
    "            if ref_idx == ref_frames.shape[0] - 1:\n",
    "                #This is the last ref frame. There are >1 ref frames.\n",
    "                ref_begin = int((ref_frames[ref_idx-1]+ref_frames[ref_idx])/2)\n",
    "                ref_end = n_frames\n",
    "            else:\n",
    "                #These are ref frames in the middle. There are >1 ref frames.\n",
    "                ref_begin = int((ref_frames[ref_idx-1]+ref_frames[ref_idx])/2)\n",
    "                ref_end = int((ref_frames[ref_idx]+ref_frames[ref_idx+1])/2)\n",
    "        \n",
    "        ref_mask = ref_masks[ref_idx]\n",
    "        h = ref_mask.shape[0]\n",
    "        w = ref_mask.shape[1]\n",
    "        x0 = int((w-min_w)/2)\n",
    "        y0 = int((h-min_h)/2)\n",
    "        \n",
    "        seg_masks[ref_begin:ref_end] = ref_mask[y0:y0+min_h, x0:x0+min_w]   #broadcast\n",
    "        \n",
    "    return seg_masks\n",
    "\n",
    "\n",
    "\n",
    "def create_segmentation_masks200(ref_frames, ref_masks, n_frames, ROI_w, ROI_h):\n",
    "    \n",
    "    min_h = min([m.shape[0] for m in ref_masks])\n",
    "    min_w = min([m.shape[1] for m in ref_masks])\n",
    "    \n",
    "    seg_masks = np.zeros((n_frames, ROI_h, ROI_w))\n",
    "    \n",
    "    for ref_idx in range(ref_frames.shape[0]):\n",
    "        ref_frame = ref_frames[ref_idx]\n",
    "        \n",
    "        #compute the temporal segment the ref_frame is responsible for\n",
    "        if ref_idx == 0:\n",
    "            if ref_idx == ref_frames.shape[0] - 1:\n",
    "                #There is only 1 ref_frame\n",
    "                ref_begin = 0\n",
    "                ref_end = n_frames\n",
    "            else:\n",
    "                #This is the first ref_frame. There are >1 ref frames.\n",
    "                ref_begin = 0\n",
    "                ref_end = int((ref_frames[ref_idx]+ref_frames[ref_idx+1])/2)\n",
    "        else:\n",
    "            if ref_idx == ref_frames.shape[0] - 1:\n",
    "                #This is the last ref frame. There are >1 ref frames.\n",
    "                ref_begin = int((ref_frames[ref_idx-1]+ref_frames[ref_idx])/2)\n",
    "                ref_end = n_frames\n",
    "            else:\n",
    "                #These are ref frames in the middle. There are >1 ref frames.\n",
    "                ref_begin = int((ref_frames[ref_idx-1]+ref_frames[ref_idx])/2)\n",
    "                ref_end = int((ref_frames[ref_idx]+ref_frames[ref_idx+1])/2)\n",
    "        \n",
    "        ref_mask = ref_masks[ref_idx]\n",
    "        h = ref_mask.shape[0]\n",
    "        w = ref_mask.shape[1]\n",
    "        x0 = int((w-min_w)/2)\n",
    "        y0 = int((h-min_h)/2)\n",
    "        \n",
    "        top_offset = int((ROI_h-min_h)/2)\n",
    "        left_offset = int((ROI_w-min_w)/2)\n",
    "        seg_masks[ref_begin:ref_end, top_offset:top_offset+min_h, left_offset:left_offset+min_w] = ref_mask[y0:y0+min_h, x0:x0+min_w]   #broadcast\n",
    "        \n",
    "    return seg_masks\n",
    "\n",
    "\n",
    "\n",
    "def create_ori_bboxes(ref_frames, ref_bboxes, n_frames):\n",
    "    min_h = min([b[3] for b in ref_bboxes])\n",
    "    min_w = min([b[2] for b in ref_bboxes])\n",
    "    \n",
    "    ori_bboxes = np.zeros((n_frames, 4))\n",
    "    \n",
    "    for ref_idx in range(ref_frames.shape[0]):\n",
    "        ref_frame = ref_frames[ref_idx]\n",
    "        \n",
    "        #compute the temporal segment the ref_frame is responsible for\n",
    "        if ref_idx == 0:\n",
    "            if ref_idx == ref_frames.shape[0] - 1:\n",
    "                #There is only 1 ref_frame\n",
    "                ref_begin = 0\n",
    "                ref_end = n_frames\n",
    "            else:\n",
    "                #This is the first ref_frame. There are >1 ref frames.\n",
    "                ref_begin = 0\n",
    "                ref_end = int((ref_frames[ref_idx]+ref_frames[ref_idx+1])/2)\n",
    "        else:\n",
    "            if ref_idx == ref_frames.shape[0] - 1:\n",
    "                #This is the last ref frame. There are >1 ref frames.\n",
    "                ref_begin = int((ref_frames[ref_idx-1]+ref_frames[ref_idx])/2)\n",
    "                ref_end = n_frames\n",
    "            else:\n",
    "                #These are ref frames in the middle. There are >1 ref frames.\n",
    "                ref_begin = int((ref_frames[ref_idx-1]+ref_frames[ref_idx])/2)\n",
    "                ref_end = int((ref_frames[ref_idx]+ref_frames[ref_idx+1])/2)\n",
    "        \n",
    "        x0,y0,w,h = ref_bboxes[ref_idx]\n",
    "        new_w = min_w\n",
    "        new_h = min_h\n",
    "        new_x0 = x0 + int((w-new_w)/2)\n",
    "        new_y0 = y0 + int((h-new_h)/2)\n",
    "        \n",
    "        new_bbox = np.array([new_x0, new_y0, new_w, new_h])\n",
    "        \n",
    "        ori_bboxes[ref_begin:ref_end] = new_bbox   #broadcast\n",
    "        \n",
    "    return ori_bboxes\n",
    "\n",
    "\n",
    "\n",
    "def create_CE_ori_bboxes(bmode_bboxes, x0_bmode, x0_CE, CE_side):\n",
    "    CE_bboxes = bmode_bboxes.copy()\n",
    "        \n",
    "    if CE_side == 'r':\n",
    "        CE_bboxes[:,0] = CE_bboxes[:,0] + (x0_CE-x0_bmode)\n",
    "    elif CE_side == 'l':\n",
    "        CE_bboxes[:,0] = CE_bboxes[:,0] - (x0_bmode-x0_CE)\n",
    "    else:\n",
    "        raise Exception('Error in create_CE_ori_bboxes')\n",
    "            \n",
    "    return CE_bboxes\n",
    "\n",
    "\n",
    "\n",
    "def cut_ROI(full_array, bboxes):\n",
    "    \n",
    "    min_w = min([b[2] for b in bboxes if not(b is None)])\n",
    "    min_h = min([b[3] for b in bboxes if not(b is None)])\n",
    "    \n",
    "    ROI = np.zeros((full_array.shape[0], min_h, min_w))\n",
    "    \n",
    "    for frame in range(full_array.shape[0]):\n",
    "        bbox = bboxes[frame]\n",
    "        if bbox is None:  #skip MC frames without bbox (due to out-of-frame motion)\n",
    "            continue\n",
    "        x0,y0,w,h = bbox\n",
    "        ROI[frame] = full_array[frame, y0:y0+h, x0:x0+w]\n",
    "    \n",
    "    return ROI\n",
    "\n",
    "\n",
    "\n",
    "def cut_ROI200(full_array, bboxes, window_loc):\n",
    "    \n",
    "    min_w = min([b[2] for b in bboxes if not(b is None)])\n",
    "    min_h = min([b[3] for b in bboxes if not(b is None)])\n",
    "    \n",
    "    window_x0, window_y0, window_w, window_h = window_loc\n",
    "    \n",
    "    cut_h = int(max(0.4*window_h, min_h, min_w))\n",
    "    cut_w = cut_h\n",
    "    \n",
    "    ROI = np.zeros((full_array.shape[0], cut_h, cut_w))\n",
    "    \n",
    "    for frame in range(full_array.shape[0]):\n",
    "        bbox = bboxes[frame]\n",
    "        if bbox is None:  #skip MC frames without bbox (due to out-of-frame motion)\n",
    "            continue\n",
    "        x0,y0,w,h = bbox\n",
    "        x_center = x0 + int(w/2)\n",
    "        y_center = y0 + int(h/2)\n",
    "        valid_w = min(int(x_center+cut_w/2),window_x0+window_w) - max(int(x_center-cut_w/2),window_x0)\n",
    "        valid_h = min(int(y_center+cut_h/2),window_y0+window_h) - max(int(y_center-cut_h/2),window_y0)\n",
    "        center_ROI = int(cut_h/2)\n",
    "        ROI[frame, int(center_ROI-valid_h/2):int(center_ROI+valid_h/2), int(center_ROI-valid_w/2):int(center_ROI+valid_w/2)] = full_array[frame, \n",
    "                                max(int(y_center-cut_h/2),window_y0):min(int(y_center+cut_h/2),window_y0+window_h), \n",
    "                                max(int(x_center-cut_w/2),window_x0):min(int(x_center+cut_w/2),window_x0+window_w)]\n",
    "    \n",
    "    return ROI\n",
    "\n",
    "\n",
    "\n",
    "def visualize_ROI(bmode_ori_ROI, CE_ori_ROI, bmode_MC_ROI, CE_MC_ROI, seg_masks):\n",
    "    n_frames = bmode_ori_ROI.shape[0]\n",
    "    \n",
    "    for frame in range(min(n_frames,100)):\n",
    "        print('frame:', frame)\n",
    "        plt.figure()\n",
    "        plt.subplot(1,5,1)\n",
    "        plt.imshow(bmode_ori_ROI[frame], cmap='gray')\n",
    "        plt.subplot(1,5,2)\n",
    "        plt.imshow(CE_ori_ROI[frame], cmap='gray')\n",
    "        plt.subplot(1,5,3)\n",
    "        plt.imshow(bmode_MC_ROI[frame], cmap='gray')\n",
    "        plt.subplot(1,5,4)\n",
    "        plt.imshow(CE_MC_ROI[frame], cmap='gray')\n",
    "        plt.subplot(1,5,5)\n",
    "        plt.imshow(seg_masks[frame], cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "        \n",
    "def export_pickle(cine_array, pickle_path):\n",
    "    \n",
    "    pickle_dir = dirname(pickle_path)\n",
    "    if not exists(pickle_dir):\n",
    "        os.makedirs(pickle_dir)\n",
    "\n",
    "    with open(pickle_path, 'wb') as wr:\n",
    "        pickle.dump(cine_array, wr, protocol=4)\n",
    "        \n",
    "        \n",
    "        \n",
    "def remove_outlier_bboxes(bboxes, full_array):\n",
    "    \n",
    "    all_x0 = [b[0] for b in bboxes if not(b is None)]\n",
    "    median_x0 = np.median(all_x0)\n",
    "    q1_x0 = np.quantile(all_x0, 0.25)\n",
    "    q3_x0 = np.quantile(all_x0, 0.75)\n",
    "    IQR_x0 = q3_x0 - q1_x0\n",
    "    \n",
    "    all_y0 = [b[1] for b in bboxes if not(b is None)]\n",
    "    median_y0 = np.median(all_y0)\n",
    "    q1_y0 = np.quantile(all_y0, 0.25)\n",
    "    q3_y0 = np.quantile(all_y0, 0.75)\n",
    "    IQR_y0 = q3_y0 - q1_y0\n",
    "    \n",
    "    out_bboxes = [None]*len(bboxes)\n",
    "    outliers = [None]*len(bboxes)\n",
    "    for i,b in enumerate(bboxes):\n",
    "        if not(b is None):\n",
    "            if (b[0]>=q1_x0-(1.5*IQR_x0)) and (b[0]<=q3_x0+(1.5*IQR_x0)) and \\\n",
    "            (b[1]>=q1_y0-(1.5*IQR_y0)) and (b[1]<=q3_y0+(1.5*IQR_y0)):\n",
    "                out_bboxes[i] = b[:]\n",
    "            else:\n",
    "                outliers[i] = b[:]\n",
    "                \n",
    "    print('usable bboxes:', len([b for b in out_bboxes if not(b is None)]))\n",
    "    print('outlier bboxes:', len([b for b in outliers if not(b is None)]))\n",
    "    \n",
    "    return out_bboxes\n",
    "\n",
    "\n",
    "\n",
    "def perform_MC(pickle_full_path, nifti_segmentation_path, mp4_path,\n",
    "              ROI_margin_suffix, frame_rate_suffix):\n",
    "    \n",
    "    if frame_rate_suffix == 'fullFrameRate':\n",
    "        step = 1\n",
    "    elif frame_rate_suffix == 'halfFrameRate':\n",
    "        step = 2\n",
    "    \n",
    "    full_array = load_pickle(pickle_full_path).astype(np.uint8)\n",
    "    \n",
    "    full_h = full_array.shape[1]\n",
    "    search_margin = int((0.5/15)*full_h)\n",
    "\n",
    "    ref_frames, bboxes, masks = find_ref_frames_from_nifti(nifti_segmentation_path, ROI_margin_suffix, search_margin)\n",
    "\n",
    "    #############################################################\n",
    "    #find initial correlation in the first run\n",
    "    min_x0 = min([e[0] for e in bboxes]) - search_margin\n",
    "    max_x1 = max([e[0]+e[2] for e in bboxes]) + search_margin\n",
    "    min_y0 = min([e[1] for e in bboxes]) - search_margin\n",
    "    max_y1 = max([e[1]+e[3] for e in bboxes]) + search_margin\n",
    "    bmode = full_array[:,\n",
    "                  min_y0:max_y1,\n",
    "                  min_x0:max_x1]\n",
    "    ref_bmodes = []\n",
    "    for ri in range(ref_frames.shape[0]):\n",
    "        ref_f = ref_frames[ri]\n",
    "        ref_b = bboxes[ri]\n",
    "        ref_bmodes.append(full_array[ref_f,\n",
    "                                    ref_b[1]:ref_b[1]+ref_b[3],\n",
    "                                    ref_b[0]:ref_b[0]+ref_b[2]])\n",
    "    corr_initial_run, threshold = find_correlation(bmode, ref_bmodes, set_quantile)\n",
    "    print('initial threshold:', threshold)\n",
    "    ############################################################\n",
    "    \n",
    "    ref_patches = ref_bmodes[:]\n",
    "    \n",
    "    previous_all_lesion_bboxes = [None]*full_array.shape[0]\n",
    "    iteration = 1\n",
    "        \n",
    "    while True:\n",
    "        \n",
    "        out_array = np.zeros(list(full_array.shape)+[3], dtype=np.uint8)\n",
    "        \n",
    "        all_search_bboxes = [None]*full_array.shape[0]\n",
    "        all_lesion_bboxes = [None]*full_array.shape[0]\n",
    "        corr_with_ref = [None]*full_array.shape[0]\n",
    "    \n",
    "        for ref_idx in range(ref_frames.shape[0]):\n",
    "            ref_frame = ref_frames[ref_idx]\n",
    "            ref_bbox = bboxes[ref_idx]\n",
    "\n",
    "            #show location of the ref_bbox\n",
    "            if iteration == 1 and ref_idx==0:\n",
    "                img_bbox = cv2.rectangle(cv2.cvtColor(full_array[ref_frame], cv2.COLOR_GRAY2BGR),\n",
    "                                             (ref_bbox[0], ref_bbox[1]),\n",
    "                                             (ref_bbox[0] + ref_bbox[2], ref_bbox[1] + ref_bbox[3]),\n",
    "                                             (0, 255, 0), 5)\n",
    "                plt.imshow(img_bbox)\n",
    "                plt.show()\n",
    "\n",
    "            #compute the temporal segment the ref_frame is responsible for\n",
    "            #######################\n",
    "            if ref_idx == 0:\n",
    "                if ref_idx == ref_frames.shape[0] - 1:\n",
    "                    #There is only 1 ref_frame\n",
    "                    ref_begin = 0\n",
    "                    ref_end = full_array.shape[0]\n",
    "                else:\n",
    "                    #This is the first ref_frame. There are >1 ref frames.\n",
    "                    ref_begin = 0\n",
    "                    ref_end = int((ref_frames[ref_idx]+ref_frames[ref_idx+1])/2)\n",
    "            else:\n",
    "                if ref_idx == ref_frames.shape[0] - 1:\n",
    "                    #This is the last ref frame. There are >1 ref frames.\n",
    "                    ref_begin = int((ref_frames[ref_idx-1]+ref_frames[ref_idx])/2)\n",
    "                    ref_end = full_array.shape[0]\n",
    "                else:\n",
    "                    #These are ref frames in the middle. There are >1 ref frames.\n",
    "                    ref_begin = int((ref_frames[ref_idx-1]+ref_frames[ref_idx])/2)\n",
    "                    ref_end = int((ref_frames[ref_idx]+ref_frames[ref_idx+1])/2)\n",
    "            #######################\n",
    "\n",
    "            #forward tracking\n",
    "            ##############################################################\n",
    "            if ref_frame < ref_end-1:  #can forward track only if there are frames after the ref_frame\n",
    "                previous_bbox = ref_bbox\n",
    "                valid = True\n",
    "\n",
    "                for frame in range(ref_frame, ref_end, step):\n",
    "\n",
    "                    full_frame = full_array[frame]\n",
    "\n",
    "                    if valid:\n",
    "                        search_w = int(previous_bbox[2]+(2*search_margin))\n",
    "                        search_h = int(previous_bbox[3]+(2*search_margin))\n",
    "                        search_x0 = int(previous_bbox[0] - ((search_w - previous_bbox[2])/2))\n",
    "                        search_y0 = int(previous_bbox[1] - ((search_h - previous_bbox[3])/2))\n",
    "                        search_bbox = (search_x0, search_y0, search_w, search_h)\n",
    "                        search_region = full_frame[search_y0:search_y0+search_h,\n",
    "                                                  search_x0:search_x0+search_w]\n",
    "\n",
    "                        all_search_bboxes[frame] = search_bbox\n",
    "\n",
    "                    else:\n",
    "                        all_search_x0 = [b[0] for b in all_search_bboxes[ref_frame+1:ref_end] if not(b is None)]\n",
    "                        median_x0 = np.median(all_search_x0)\n",
    "                        IQR_x0 = np.quantile(all_search_x0, 0.75) - np.quantile(all_search_x0, 0.25)\n",
    "                        all_search_x0 = [x for x in all_search_x0 if (x>=median_x0-(1.5*IQR_x0)) and (x<=median_x0+(1.5*IQR_x0))]\n",
    "                        min_search_x0 = min(all_search_x0)\n",
    "                        max_search_x0 = max(all_search_x0)\n",
    "\n",
    "                        all_search_y0 = [b[1] for b in all_search_bboxes[ref_frame+1:ref_end] if not(b is None)]\n",
    "                        median_y0 = np.median(all_search_y0)\n",
    "                        IQR_y0 = np.quantile(all_search_y0, 0.75) - np.quantile(all_search_y0, 0.25)\n",
    "                        all_search_y0 = [y for y in all_search_y0 if (y>=median_y0-(1.5*IQR_y0)) and (y<=median_y0+(1.5*IQR_y0))]\n",
    "                        min_search_y0 = min(all_search_y0)\n",
    "                        max_search_y0 = max(all_search_y0)\n",
    "\n",
    "                        search_x0 = min_search_x0\n",
    "                        search_y0 = min_search_y0\n",
    "                        search_w = (max_search_x0-min_search_x0) + int(ref_bbox[2]+(2*search_margin))\n",
    "                        search_h = (max_search_y0-min_search_y0) + int(previous_bbox[3]+(2*search_margin))\n",
    "                        search_bbox = (search_x0, search_y0, search_w, search_h)\n",
    "                        search_region = full_frame[search_y0:search_y0+search_h,\n",
    "                                                      search_x0:search_x0+search_w]    \n",
    "\n",
    "                    mean_corr, max_loc = compute_similarity_map(search_region, ref_patches, ref_idx)\n",
    "                    corr_with_ref[frame] = mean_corr\n",
    "                    \n",
    "                    if mean_corr >= threshold:\n",
    "                        valid = True\n",
    "                        current_w = ref_bbox[2]\n",
    "                        current_h = ref_bbox[3]\n",
    "                        current_x0 = search_x0 + max_loc[0]\n",
    "                        current_y0 = search_y0 + max_loc[1]\n",
    "                        current_bbox = (current_x0, current_y0, current_w, current_h)\n",
    "\n",
    "                        img_bbox = cv2.rectangle(cv2.cvtColor(full_frame, cv2.COLOR_GRAY2BGR),\n",
    "                                                     (search_x0, search_y0),\n",
    "                                                     (search_x0+search_w, search_y0+search_h),\n",
    "                                                     (255, 255, 255), 2)\n",
    "                        img_bbox = cv2.rectangle(img_bbox,\n",
    "                                                     (current_bbox[0], current_bbox[1]),\n",
    "                                                     (current_bbox[0] + current_bbox[2], current_bbox[1] + current_bbox[3]),\n",
    "                                                     (0, 255, 0), 2)\n",
    "                        img_bbox = cv2.putText(img_bbox, 'frame: '+str(frame), (25,25), cv2.FONT_HERSHEY_SIMPLEX,  \n",
    "                                       1, (0,255,0), 2, cv2.LINE_AA) \n",
    "                        img_bbox = cv2.putText(img_bbox, 'corr: '+str(mean_corr), (25,50), cv2.FONT_HERSHEY_SIMPLEX,  \n",
    "                                       1, (0,255,0), 2, cv2.LINE_AA) \n",
    "\n",
    "                        out_array[frame] = img_bbox\n",
    "\n",
    "                        all_lesion_bboxes[frame] = current_bbox[:]\n",
    "                        previous_bbox = current_bbox[:]\n",
    "                        \n",
    "                    else:\n",
    "                        valid = False\n",
    "                        img_bbox = cv2.rectangle(cv2.cvtColor(full_frame, cv2.COLOR_GRAY2BGR),\n",
    "                                                     (search_x0, search_y0),\n",
    "                                                     (search_x0+search_w, search_y0+search_h),\n",
    "                                                     (0, 0, 255), 2)\n",
    "                        img_bbox = cv2.putText(img_bbox, 'frame: '+str(frame), (25,25), cv2.FONT_HERSHEY_SIMPLEX,  \n",
    "                                       1, (0,0,255), 2, cv2.LINE_AA) \n",
    "                        img_bbox = cv2.putText(img_bbox, 'corr: '+str(mean_corr), (25,50), cv2.FONT_HERSHEY_SIMPLEX,  \n",
    "                                       1, (0,0,255), 2, cv2.LINE_AA) \n",
    "\n",
    "                        out_array[frame] = img_bbox\n",
    "            ##############################################################\n",
    "            \n",
    "            #backward tracking\n",
    "            ##############################################################\n",
    "            if ref_frame > ref_begin:  \n",
    "                previous_bbox = ref_bbox\n",
    "                valid = True\n",
    "\n",
    "                for frame in range(ref_frame-1, ref_begin-1, -step):\n",
    "\n",
    "                    full_frame = full_array[frame]\n",
    "\n",
    "                    if valid:\n",
    "                        search_w = int(previous_bbox[2]+(2*search_margin))\n",
    "                        search_h = int(previous_bbox[3]+(2*search_margin))\n",
    "                        search_x0 = int(previous_bbox[0] - ((search_w - previous_bbox[2])/2))\n",
    "                        search_y0 = int(previous_bbox[1] - ((search_h - previous_bbox[3])/2))\n",
    "                        search_bbox = (search_x0, search_y0, search_w, search_h)\n",
    "                        search_region = full_frame[search_y0:search_y0+search_h,\n",
    "                                                  search_x0:search_x0+search_w]\n",
    "\n",
    "                        all_search_bboxes[frame] = search_bbox\n",
    "\n",
    "                    else:\n",
    "                        all_search_x0 = [b[0] for b in all_search_bboxes[ref_begin:ref_frame] if not(b is None)]\n",
    "                        median_x0 = np.median(all_search_x0)\n",
    "                        IQR_x0 = np.quantile(all_search_x0, 0.75) - np.quantile(all_search_x0, 0.25)\n",
    "                        all_search_x0 = [x for x in all_search_x0 if (x>=median_x0-(1.5*IQR_x0)) and (x<=median_x0+(1.5*IQR_x0))]\n",
    "                        min_search_x0 = min(all_search_x0)\n",
    "                        max_search_x0 = max(all_search_x0)\n",
    "\n",
    "                        all_search_y0 = [b[1] for b in all_search_bboxes[ref_begin:ref_frame] if not(b is None)]\n",
    "                        median_y0 = np.median(all_search_y0)\n",
    "                        IQR_y0 = np.quantile(all_search_y0, 0.75) - np.quantile(all_search_y0, 0.25)\n",
    "                        all_search_y0 = [y for y in all_search_y0 if (y>=median_y0-(1.5*IQR_y0)) and (y<=median_y0+(1.5*IQR_y0))]\n",
    "                        min_search_y0 = min(all_search_y0)\n",
    "                        max_search_y0 = max(all_search_y0)\n",
    "\n",
    "                        search_x0 = min_search_x0\n",
    "                        search_y0 = min_search_y0\n",
    "                        search_w = (max_search_x0-min_search_x0) + int(ref_bbox[2]+(2*search_margin))\n",
    "                        search_h = (max_search_y0-min_search_y0) + int(previous_bbox[3]+(2*search_margin))\n",
    "                        search_bbox = (search_x0, search_y0, search_w, search_h)\n",
    "                        search_region = full_frame[search_y0:search_y0+search_h,\n",
    "                                                      search_x0:search_x0+search_w]    \n",
    "\n",
    "                    mean_corr, max_loc = compute_similarity_map(search_region, ref_patches, ref_idx)\n",
    "                    corr_with_ref[frame] = mean_corr\n",
    "                    \n",
    "                    if mean_corr >= threshold:\n",
    "                        valid = True\n",
    "                        current_w = ref_bbox[2]\n",
    "                        current_h = ref_bbox[3]\n",
    "                        current_x0 = search_x0 + max_loc[0]\n",
    "                        current_y0 = search_y0 + max_loc[1]\n",
    "                        current_bbox = (current_x0, current_y0, current_w, current_h)\n",
    "\n",
    "                        img_bbox = cv2.rectangle(cv2.cvtColor(full_frame, cv2.COLOR_GRAY2BGR),\n",
    "                                                     (search_x0, search_y0),\n",
    "                                                     (search_x0+search_w, search_y0+search_h),\n",
    "                                                     (255, 255, 255), 2)\n",
    "                        img_bbox = cv2.rectangle(img_bbox,\n",
    "                                                     (current_bbox[0], current_bbox[1]),\n",
    "                                                     (current_bbox[0] + current_bbox[2], current_bbox[1] + current_bbox[3]),\n",
    "                                                     (0, 255, 0), 2)\n",
    "                        img_bbox = cv2.putText(img_bbox, 'frame: '+str(frame), (25,25), cv2.FONT_HERSHEY_SIMPLEX,  \n",
    "                                       1, (0,255,0), 2, cv2.LINE_AA) \n",
    "                        img_bbox = cv2.putText(img_bbox, 'corr: '+str(mean_corr), (25,50), cv2.FONT_HERSHEY_SIMPLEX,  \n",
    "                                       1, (0,255,0), 2, cv2.LINE_AA) \n",
    "\n",
    "                        out_array[frame] = img_bbox\n",
    "\n",
    "                        all_lesion_bboxes[frame] = current_bbox[:]\n",
    "                        previous_bbox = current_bbox[:]\n",
    "                        \n",
    "                    else:\n",
    "                        valid = False\n",
    "                        img_bbox = cv2.rectangle(cv2.cvtColor(full_frame, cv2.COLOR_GRAY2BGR),\n",
    "                                                     (search_x0, search_y0),\n",
    "                                                     (search_x0+search_w, search_y0+search_h),\n",
    "                                                     (0, 0, 255), 2)\n",
    "                        img_bbox = cv2.putText(img_bbox, 'frame: '+str(frame), (25,25), cv2.FONT_HERSHEY_SIMPLEX,  \n",
    "                                       1, (0,0,255), 2, cv2.LINE_AA) \n",
    "                        img_bbox = cv2.putText(img_bbox, 'corr: '+str(mean_corr), (25,50), cv2.FONT_HERSHEY_SIMPLEX,  \n",
    "                                       1, (0,0,255), 2, cv2.LINE_AA) \n",
    "\n",
    "                        out_array[frame] = img_bbox\n",
    "            ##############################################################\n",
    "            \n",
    "\n",
    "        #check if lesion bbox in any frame move in this iteration\n",
    "        #####################\n",
    "        bbox_move = check_bbox_move(previous_all_lesion_bboxes, all_lesion_bboxes)\n",
    "        if bbox_move or (threshold < min([e for e in corr_with_ref if not(e is None)])):\n",
    "            break\n",
    "        #####################\n",
    "\n",
    "        previous_threshold = threshold\n",
    "        previous_all_lesion_bboxes = all_lesion_bboxes[:]\n",
    "        previous_out_array = out_array.copy()\n",
    "        previous_corr_with_ref = corr_with_ref.copy()\n",
    "        threshold -= threshold_decrease_per_step\n",
    "        iteration += 1\n",
    "     \n",
    "    print('iteration:', iteration-1)\n",
    "    print('threshold:', previous_threshold)\n",
    "\n",
    "    out_array = previous_out_array.copy()\n",
    "   \n",
    "    export_video(out_array, mp4_path, CineRate=10)\n",
    "    \n",
    "    return full_array, previous_all_lesion_bboxes, ref_frames, bboxes, masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 12)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P_001\n",
      "../sample-data/P_001/pickle_bmode_CE_gray/ceus_inj1_wi_000000.000000.pkl\n",
      "(753, 802, 1442)\n",
      "(753, 802, 1442)\n",
      "initial threshold: 0.4534117877483368\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1\n",
      "threshold: 0.4534117877483368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x44495658/'XVID' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usable bboxes: 352\n",
      "outlier bboxes: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:50<00:00, 50.98s/it]\n"
     ]
    }
   ],
   "source": [
    "for ROI_margin_suffix in ROI_margin_suffix_list:\n",
    "    for frame_rate_suffix in frame_rate_suffix_list:\n",
    "        \n",
    "        export_dir = export_dir_prefix + ROI_margin_suffix + '_' + frame_rate_suffix\n",
    "        \n",
    "        df = pd.read_excel(dataset_path, dtype=str)\n",
    "        print(df.shape)\n",
    "        \n",
    "        for col in df.columns:\n",
    "            if col.endswith('_path'):\n",
    "                df.loc[:,col] = df[col].apply(add_data_dir, args=(data_dir,))\n",
    "                \n",
    "        for row_idx in tqdm(df.index):\n",
    "            patient_code_inj = df.loc[row_idx, 'patient_code_inj']\n",
    "            print(patient_code_inj)\n",
    "            pickle_full_path = df.loc[row_idx, 'pickle_bmode_CE_gray_path']\n",
    "            print(pickle_full_path)\n",
    "            mp4_path = join(export_mp4_dir, patient_code_inj+'.mp4')\n",
    "            nifti_segmentation_path = df.loc[row_idx, 'nifti_segmentation_path']\n",
    "\n",
    "            full_array, bmode_MC_bboxes, ref_frames, ref_bboxes, ref_masks = perform_MC(pickle_full_path, \n",
    "                                                                                        nifti_segmentation_path, \n",
    "                                                                                        mp4_path,\n",
    "                                                                                        ROI_margin_suffix, \n",
    "                                                                                        frame_rate_suffix)\n",
    "\n",
    "            #resize all MC bboxes to the same size\n",
    "            bmode_MC_bboxes = resize_MC_bboxes(bmode_MC_bboxes)\n",
    "\n",
    "            #remove outlier bboxes\n",
    "            bmode_MC_bboxes = remove_outlier_bboxes(bmode_MC_bboxes, full_array)\n",
    "\n",
    "            n_frames = full_array.shape[0]\n",
    "\n",
    "            x0_bmode = int(df.loc[row_idx, 'x0_bmode'])\n",
    "            y0_bmode = int(df.loc[row_idx, 'y0_bmode'])\n",
    "            w_bmode = int(df.loc[row_idx, 'w_bmode'])\n",
    "            h_bmode = int(df.loc[row_idx, 'h_bmode'])\n",
    "            x0_CE = int(df.loc[row_idx, 'x0_CE'])\n",
    "            y0_CE = int(df.loc[row_idx, 'y0_CE'])\n",
    "            w_CE = int(df.loc[row_idx, 'w_CE'])\n",
    "            h_CE = int(df.loc[row_idx, 'h_CE'])\n",
    "            CE_side = df.loc[row_idx, 'CE_window_left(l)_or_right(r)']\n",
    "\n",
    "            CE_MC_bboxes = create_CE_MC_bboxes(bmode_MC_bboxes, x0_bmode, x0_CE, CE_side)\n",
    "            bmode_ori_bboxes = create_ori_bboxes(ref_frames, ref_bboxes, n_frames).astype('int')\n",
    "            CE_ori_bboxes = create_CE_ori_bboxes(bmode_ori_bboxes, x0_bmode, x0_CE, CE_side).astype('int')\n",
    "\n",
    "            #cut ROI\n",
    "            if not fixed_size_ROI:\n",
    "                #use \"cut_ROI\" function to get ROI exactly fit to the lesion\n",
    "                bmode_MC_ROI = cut_ROI(full_array, bmode_MC_bboxes)\n",
    "                CE_MC_ROI = cut_ROI(full_array, CE_MC_bboxes)\n",
    "            else:\n",
    "                #use \"cut_ROI200\" function to get a fixed size ROI\n",
    "                bmode_MC_ROI = cut_ROI200(full_array, bmode_MC_bboxes, (x0_bmode,y0_bmode,w_bmode,h_bmode))\n",
    "                CE_MC_ROI = cut_ROI200(full_array, CE_MC_bboxes, (x0_CE,y0_CE,w_CE,h_CE))\n",
    "\n",
    "            export_pickle(bmode_MC_ROI, join(export_dir, patient_code_inj, 'bmode_MC_ROI.pkl'))\n",
    "            export_pickle(CE_MC_ROI, join(export_dir, patient_code_inj, 'CE_MC_ROI.pkl'))\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-11.m91",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-11:m91"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

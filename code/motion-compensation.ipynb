{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from os.path import join, isfile, exists, isdir, dirname\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '../sample-data/dataset_synthesize.xlsx'\n",
    "data_dir = '../sample-data'\n",
    "\n",
    "export_dir_prefix = '../outputs/'\n",
    "export_excel_path = '../outputs/motion-compensation.xlsx'\n",
    "export_mp4_dir = '../outputs/mp4-outputs'\n",
    "\n",
    "ROI_margin_suffix_list = ['withoutROImargin']  #['withROImargin', 'withoutROImargin']\n",
    "frame_rate_suffix_list = ['fullFrameRate']  #['halfFrameRate', 'fullFrameRate']\n",
    "\n",
    "fixed_size_ROI = False  #if True, the output ROIs will have a fixed size, rather than fitted to the lesion\n",
    "\n",
    "set_quantile = 0.50  #initial quantile\n",
    "threshold_decrease_per_step = 0.02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_data_dir(x, data_dir):\n",
    "    if pd.isna(x):\n",
    "        return None\n",
    "    else:\n",
    "        return join(data_dir, x)\n",
    "\n",
    "\n",
    "\n",
    "def load_pickle(pickle_path):\n",
    "    with open(pickle_path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    print(data.shape)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "def find_ref_frames_from_nifti(nifti_path, ROI_margin_suffix, search_margin):\n",
    "    \n",
    "    nifti_array = np.transpose(nib.load(nifti_path).get_fdata()).astype(int)\n",
    "    print(nifti_array.shape)  # expected (frames, height, width)\n",
    "\n",
    "    spatial_sum = np.sum(nifti_array, axis=(1, 2))  # shape (frames,)\n",
    "    ref_frames = np.argwhere(spatial_sum > 0)\n",
    "    ref_frames = np.reshape(ref_frames, ref_frames.shape[0])\n",
    "\n",
    "    if ROI_margin_suffix == 'withROImargin':\n",
    "        ROI_margin = int(search_margin/2)\n",
    "    elif ROI_margin_suffix == 'withoutROImargin':\n",
    "        ROI_margin = 0\n",
    "    \n",
    "    bboxes = []\n",
    "    masks = []\n",
    "    for i,ref_frame in enumerate(ref_frames):\n",
    "        mask = nifti_array[ref_frame]\n",
    "        pos_coor = np.argwhere(mask > 0)\n",
    "        x_values = pos_coor[:, 1]\n",
    "        y_values = pos_coor[:, 0]\n",
    "        x0 = x_values.min()\n",
    "        x1 = x_values.max()\n",
    "        w = x1 - x0 + 1\n",
    "        y0 = y_values.min()\n",
    "        y1 = y_values.max()\n",
    "        h = y1 - y0 + 1\n",
    "        \n",
    "        bboxes.append((x0-ROI_margin,\n",
    "                       y0-ROI_margin,\n",
    "                       w+(2*ROI_margin),\n",
    "                       h+(2*ROI_margin)))\n",
    "        masks.append(mask[y0-ROI_margin:y0-ROI_margin+h+(2*ROI_margin), \n",
    "                          x0-ROI_margin:x0-ROI_margin+w+(2*ROI_margin)])\n",
    "\n",
    "    return ref_frames, bboxes, masks\n",
    "\n",
    "\n",
    "\n",
    "def export_video(cine_array, mp4_path, CineRate):\n",
    "\n",
    "    mp4_dir = dirname(mp4_path)\n",
    "    if not exists(mp4_dir):\n",
    "        os.makedirs(mp4_dir)\n",
    "\n",
    "    width = cine_array.shape[2]\n",
    "    height = cine_array.shape[1]\n",
    "    if pd.notna(CineRate):\n",
    "        frame_rate = int(CineRate)\n",
    "    else:\n",
    "        print('no CineRate in excel file; using default frame rate = 9')\n",
    "        frame_rate = 9\n",
    "\n",
    "    writer = cv2.VideoWriter(mp4_path, cv2.VideoWriter_fourcc(*'XVID'), frame_rate, (width, height))\n",
    "\n",
    "    if len(cine_array.shape) == 3:  # grayscale\n",
    "        for frame in range(cine_array.shape[0]):\n",
    "            writer.write(cv2.cvtColor(cine_array[frame], cv2.COLOR_GRAY2BGR))\n",
    "    elif len(cine_array.shape) == 4:  # RGB\n",
    "        for frame in range(cine_array.shape[0]):\n",
    "            writer.write(cine_array[frame])\n",
    "    else:\n",
    "        print('color channel not compatible for video exporting; please check dimension of array.')\n",
    "\n",
    "    writer.release()\n",
    "    \n",
    "    \n",
    "    \n",
    "def apply_blur(cine_array):\n",
    "    out = np.zeros(cine_array.shape)\n",
    "    for frame in range(cine_array.shape[0]):\n",
    "        img = cine_array[frame]\n",
    "        img = cv2.GaussianBlur(img, (21, 21), 0)\n",
    "        out[frame] = img\n",
    "    out = out.astype(np.uint8)\n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "def plot_correlation(corr_with_ref, threshold):\n",
    "    plt.figure(figsize=(24,6))\n",
    "    plt.axhline(threshold, color='b')\n",
    "    plt.plot(range(len(corr_with_ref)), corr_with_ref, marker='o', color='g', label='corr_with_ref')\n",
    "    plt.ylim(0,1.0)\n",
    "    plt.ylabel('corr_coef')\n",
    "    plt.xlabel('frame')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "def find_correlation(bmode, ref_bmodes, set_quantile):\n",
    "    \n",
    "    n_refs = len(ref_bmodes)\n",
    "    n_frames = bmode.shape[0]\n",
    "    correlations = np.zeros((n_refs, n_frames))\n",
    "    \n",
    "    for ref_idx in range(n_refs):\n",
    "        ref = ref_bmodes[ref_idx]\n",
    "        for frame in range(n_frames):\n",
    "            similarity_map = cv2.matchTemplate(bmode[frame], ref, cv2.TM_CCOEFF_NORMED)\n",
    "            min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(similarity_map)\n",
    "            correlations[ref_idx, frame] = max_val\n",
    "            \n",
    "    correlations = np.mean(correlations, axis=0)\n",
    "    threshold = np.quantile(correlations, set_quantile)\n",
    "    \n",
    "    return correlations, threshold\n",
    "\n",
    "\n",
    "\n",
    "def check_bbox_move(previous_all_lesion_bboxes, all_lesion_bboxes):\n",
    "    \n",
    "    bbox_move = False\n",
    "    \n",
    "    for frame in range(len(previous_all_lesion_bboxes)):\n",
    "        previous_bbox = previous_all_lesion_bboxes[frame]\n",
    "        current_bbox = all_lesion_bboxes[frame]\n",
    "        if not(previous_bbox is None):\n",
    "            if not(previous_bbox == current_bbox):\n",
    "                bbox_move = True\n",
    "                break\n",
    "    \n",
    "    return bbox_move\n",
    "\n",
    "\n",
    "\n",
    "def compute_similarity_map(search_region, ref_patches, current_ref_idx):\n",
    "    \n",
    "    n_refs = len(ref_patches)\n",
    "    corrs = np.zeros((n_refs,))\n",
    "    \n",
    "    for ref_idx in range(n_refs):\n",
    "        ref = ref_patches[ref_idx]\n",
    "        similarity_map = cv2.matchTemplate(search_region, ref, cv2.TM_CCOEFF_NORMED)\n",
    "        min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(similarity_map)\n",
    "        corrs[ref_idx] = max_val\n",
    "        if current_ref_idx == ref_idx:\n",
    "            current_max_loc = max_loc\n",
    "            \n",
    "    mean_corr = np.mean(corrs)\n",
    "            \n",
    "    return mean_corr, current_max_loc\n",
    "\n",
    "\n",
    "\n",
    "def resize_MC_bboxes(bboxes):\n",
    "    #resize bboxes to minimum width and height\n",
    "    \n",
    "    min_w = min([b[2] for b in bboxes if not(b is None)])\n",
    "    min_h = min([b[3] for b in bboxes if not(b is None)])\n",
    "    \n",
    "    for i in range(len(bboxes)):\n",
    "        if bboxes[i] is None:\n",
    "            continue\n",
    "        x0, y0, w, h = bboxes[i]\n",
    "        new_w = min_w\n",
    "        new_h = min_h\n",
    "        new_x0 = x0 + int((w-new_w)/2)\n",
    "        new_y0 = y0 + int((h-new_h)/2)\n",
    "        bboxes[i] = (new_x0, new_y0, new_w, new_h)\n",
    "        \n",
    "    return bboxes\n",
    "\n",
    "\n",
    "\n",
    "def create_CE_MC_bboxes(bmode_bboxes, x0_bmode, x0_CE, CE_side):\n",
    "    \n",
    "    CE_bboxes = [None] * len(bmode_bboxes)\n",
    "    \n",
    "    for i in range(len(bmode_bboxes)):\n",
    "        if bmode_bboxes[i] is None:\n",
    "            continue\n",
    "        x0, y0, w, h = bmode_bboxes[i]\n",
    "        \n",
    "        if CE_side == 'r':\n",
    "            new_x0 = x0 + (x0_CE-x0_bmode)\n",
    "        elif CE_side == 'l':\n",
    "            new_x0 = x0 - (x0_bmode-x0_CE)\n",
    "        else:\n",
    "            raise Exception('Error in create_CE_MC_bboxes')\n",
    "            \n",
    "        CE_bboxes[i] = (new_x0, y0, w, h)\n",
    "    \n",
    "    return CE_bboxes\n",
    "\n",
    "\n",
    "\n",
    "def create_segmentation_masks(ref_frames, ref_masks, n_frames):\n",
    "    \n",
    "    min_h = min([m.shape[0] for m in ref_masks])\n",
    "    min_w = min([m.shape[1] for m in ref_masks])\n",
    "    \n",
    "    seg_masks = np.zeros((n_frames, min_h, min_w))\n",
    "    \n",
    "    for ref_idx in range(ref_frames.shape[0]):\n",
    "        ref_frame = ref_frames[ref_idx]\n",
    "        \n",
    "        #compute the temporal segment the ref_frame is responsible for\n",
    "        if ref_idx == 0:\n",
    "            if ref_idx == ref_frames.shape[0] - 1:\n",
    "                #There is only 1 ref_frame\n",
    "                ref_begin = 0\n",
    "                ref_end = n_frames\n",
    "            else:\n",
    "                #This is the first ref_frame. There are >1 ref frames.\n",
    "                ref_begin = 0\n",
    "                ref_end = int((ref_frames[ref_idx]+ref_frames[ref_idx+1])/2)\n",
    "        else:\n",
    "            if ref_idx == ref_frames.shape[0] - 1:\n",
    "                #This is the last ref frame. There are >1 ref frames.\n",
    "                ref_begin = int((ref_frames[ref_idx-1]+ref_frames[ref_idx])/2)\n",
    "                ref_end = n_frames\n",
    "            else:\n",
    "                #These are ref frames in the middle. There are >1 ref frames.\n",
    "                ref_begin = int((ref_frames[ref_idx-1]+ref_frames[ref_idx])/2)\n",
    "                ref_end = int((ref_frames[ref_idx]+ref_frames[ref_idx+1])/2)\n",
    "        \n",
    "        ref_mask = ref_masks[ref_idx]\n",
    "        h = ref_mask.shape[0]\n",
    "        w = ref_mask.shape[1]\n",
    "        x0 = int((w-min_w)/2)\n",
    "        y0 = int((h-min_h)/2)\n",
    "        \n",
    "        seg_masks[ref_begin:ref_end] = ref_mask[y0:y0+min_h, x0:x0+min_w]   #broadcast\n",
    "        \n",
    "    return seg_masks\n",
    "\n",
    "\n",
    "\n",
    "def create_segmentation_masks200(ref_frames, ref_masks, n_frames, ROI_w, ROI_h):\n",
    "    \n",
    "    min_h = min([m.shape[0] for m in ref_masks])\n",
    "    min_w = min([m.shape[1] for m in ref_masks])\n",
    "    \n",
    "    seg_masks = np.zeros((n_frames, ROI_h, ROI_w))\n",
    "    \n",
    "    for ref_idx in range(ref_frames.shape[0]):\n",
    "        ref_frame = ref_frames[ref_idx]\n",
    "        \n",
    "        #compute the temporal segment the ref_frame is responsible for\n",
    "        if ref_idx == 0:\n",
    "            if ref_idx == ref_frames.shape[0] - 1:\n",
    "                #There is only 1 ref_frame\n",
    "                ref_begin = 0\n",
    "                ref_end = n_frames\n",
    "            else:\n",
    "                #This is the first ref_frame. There are >1 ref frames.\n",
    "                ref_begin = 0\n",
    "                ref_end = int((ref_frames[ref_idx]+ref_frames[ref_idx+1])/2)\n",
    "        else:\n",
    "            if ref_idx == ref_frames.shape[0] - 1:\n",
    "                #This is the last ref frame. There are >1 ref frames.\n",
    "                ref_begin = int((ref_frames[ref_idx-1]+ref_frames[ref_idx])/2)\n",
    "                ref_end = n_frames\n",
    "            else:\n",
    "                #These are ref frames in the middle. There are >1 ref frames.\n",
    "                ref_begin = int((ref_frames[ref_idx-1]+ref_frames[ref_idx])/2)\n",
    "                ref_end = int((ref_frames[ref_idx]+ref_frames[ref_idx+1])/2)\n",
    "        \n",
    "        ref_mask = ref_masks[ref_idx]\n",
    "        h = ref_mask.shape[0]\n",
    "        w = ref_mask.shape[1]\n",
    "        x0 = int((w-min_w)/2)\n",
    "        y0 = int((h-min_h)/2)\n",
    "        \n",
    "        top_offset = int((ROI_h-min_h)/2)\n",
    "        left_offset = int((ROI_w-min_w)/2)\n",
    "        seg_masks[ref_begin:ref_end, top_offset:top_offset+min_h, left_offset:left_offset+min_w] = ref_mask[y0:y0+min_h, x0:x0+min_w]   #broadcast\n",
    "        \n",
    "    return seg_masks\n",
    "\n",
    "\n",
    "\n",
    "def create_ori_bboxes(ref_frames, ref_bboxes, n_frames):\n",
    "    min_h = min([b[3] for b in ref_bboxes])\n",
    "    min_w = min([b[2] for b in ref_bboxes])\n",
    "    \n",
    "    ori_bboxes = np.zeros((n_frames, 4))\n",
    "    \n",
    "    for ref_idx in range(ref_frames.shape[0]):\n",
    "        ref_frame = ref_frames[ref_idx]\n",
    "        \n",
    "        #compute the temporal segment the ref_frame is responsible for\n",
    "        if ref_idx == 0:\n",
    "            if ref_idx == ref_frames.shape[0] - 1:\n",
    "                #There is only 1 ref_frame\n",
    "                ref_begin = 0\n",
    "                ref_end = n_frames\n",
    "            else:\n",
    "                #This is the first ref_frame. There are >1 ref frames.\n",
    "                ref_begin = 0\n",
    "                ref_end = int((ref_frames[ref_idx]+ref_frames[ref_idx+1])/2)\n",
    "        else:\n",
    "            if ref_idx == ref_frames.shape[0] - 1:\n",
    "                #This is the last ref frame. There are >1 ref frames.\n",
    "                ref_begin = int((ref_frames[ref_idx-1]+ref_frames[ref_idx])/2)\n",
    "                ref_end = n_frames\n",
    "            else:\n",
    "                #These are ref frames in the middle. There are >1 ref frames.\n",
    "                ref_begin = int((ref_frames[ref_idx-1]+ref_frames[ref_idx])/2)\n",
    "                ref_end = int((ref_frames[ref_idx]+ref_frames[ref_idx+1])/2)\n",
    "        \n",
    "        x0,y0,w,h = ref_bboxes[ref_idx]\n",
    "        new_w = min_w\n",
    "        new_h = min_h\n",
    "        new_x0 = x0 + int((w-new_w)/2)\n",
    "        new_y0 = y0 + int((h-new_h)/2)\n",
    "        \n",
    "        new_bbox = np.array([new_x0, new_y0, new_w, new_h])\n",
    "        \n",
    "        ori_bboxes[ref_begin:ref_end] = new_bbox   #broadcast\n",
    "        \n",
    "    return ori_bboxes\n",
    "\n",
    "\n",
    "\n",
    "def create_CE_ori_bboxes(bmode_bboxes, x0_bmode, x0_CE, CE_side):\n",
    "    CE_bboxes = bmode_bboxes.copy()\n",
    "        \n",
    "    if CE_side == 'r':\n",
    "        CE_bboxes[:,0] = CE_bboxes[:,0] + (x0_CE-x0_bmode)\n",
    "    elif CE_side == 'l':\n",
    "        CE_bboxes[:,0] = CE_bboxes[:,0] - (x0_bmode-x0_CE)\n",
    "    else:\n",
    "        raise Exception('Error in create_CE_ori_bboxes')\n",
    "            \n",
    "    return CE_bboxes\n",
    "\n",
    "\n",
    "\n",
    "def cut_ROI(full_array, bboxes):\n",
    "    \n",
    "    min_w = min([b[2] for b in bboxes if not(b is None)])\n",
    "    min_h = min([b[3] for b in bboxes if not(b is None)])\n",
    "    \n",
    "    ROI = np.zeros((full_array.shape[0], min_h, min_w))\n",
    "    \n",
    "    for frame in range(full_array.shape[0]):\n",
    "        bbox = bboxes[frame]\n",
    "        if bbox is None:  #skip MC frames without bbox (due to out-of-frame motion)\n",
    "            continue\n",
    "        x0,y0,w,h = bbox\n",
    "        ROI[frame] = full_array[frame, y0:y0+h, x0:x0+w]\n",
    "    \n",
    "    return ROI\n",
    "\n",
    "\n",
    "\n",
    "def cut_ROI200(full_array, bboxes, window_loc):\n",
    "    \n",
    "    min_w = min([b[2] for b in bboxes if not(b is None)])\n",
    "    min_h = min([b[3] for b in bboxes if not(b is None)])\n",
    "    \n",
    "    window_x0, window_y0, window_w, window_h = window_loc\n",
    "    \n",
    "    cut_h = int(max(0.4*window_h, min_h, min_w))\n",
    "    cut_w = cut_h\n",
    "    \n",
    "    ROI = np.zeros((full_array.shape[0], cut_h, cut_w))\n",
    "    \n",
    "    for frame in range(full_array.shape[0]):\n",
    "        bbox = bboxes[frame]\n",
    "        if bbox is None:  #skip MC frames without bbox (due to out-of-frame motion)\n",
    "            continue\n",
    "        x0,y0,w,h = bbox\n",
    "        x_center = x0 + int(w/2)\n",
    "        y_center = y0 + int(h/2)\n",
    "        valid_w = min(int(x_center+cut_w/2),window_x0+window_w) - max(int(x_center-cut_w/2),window_x0)\n",
    "        valid_h = min(int(y_center+cut_h/2),window_y0+window_h) - max(int(y_center-cut_h/2),window_y0)\n",
    "        center_ROI = int(cut_h/2)\n",
    "        ROI[frame, int(center_ROI-valid_h/2):int(center_ROI+valid_h/2), int(center_ROI-valid_w/2):int(center_ROI+valid_w/2)] = full_array[frame, \n",
    "                                max(int(y_center-cut_h/2),window_y0):min(int(y_center+cut_h/2),window_y0+window_h), \n",
    "                                max(int(x_center-cut_w/2),window_x0):min(int(x_center+cut_w/2),window_x0+window_w)]\n",
    "    \n",
    "    return ROI\n",
    "\n",
    "\n",
    "\n",
    "def visualize_ROI(bmode_ori_ROI, CE_ori_ROI, bmode_MC_ROI, CE_MC_ROI, seg_masks):\n",
    "    n_frames = bmode_ori_ROI.shape[0]\n",
    "    \n",
    "    for frame in range(min(n_frames,100)):\n",
    "        print('frame:', frame)\n",
    "        plt.figure()\n",
    "        plt.subplot(1,5,1)\n",
    "        plt.imshow(bmode_ori_ROI[frame], cmap='gray')\n",
    "        plt.subplot(1,5,2)\n",
    "        plt.imshow(CE_ori_ROI[frame], cmap='gray')\n",
    "        plt.subplot(1,5,3)\n",
    "        plt.imshow(bmode_MC_ROI[frame], cmap='gray')\n",
    "        plt.subplot(1,5,4)\n",
    "        plt.imshow(CE_MC_ROI[frame], cmap='gray')\n",
    "        plt.subplot(1,5,5)\n",
    "        plt.imshow(seg_masks[frame], cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "        \n",
    "def export_pickle(cine_array, pickle_path):\n",
    "    \n",
    "    pickle_dir = dirname(pickle_path)\n",
    "    if not exists(pickle_dir):\n",
    "        os.makedirs(pickle_dir)\n",
    "\n",
    "    with open(pickle_path, 'wb') as wr:\n",
    "        pickle.dump(cine_array, wr, protocol=4)\n",
    "        \n",
    "        \n",
    "        \n",
    "def remove_outlier_bboxes(bboxes, full_array):\n",
    "    \n",
    "    all_x0 = [b[0] for b in bboxes if not(b is None)]\n",
    "    median_x0 = np.median(all_x0)\n",
    "    q1_x0 = np.quantile(all_x0, 0.25)\n",
    "    q3_x0 = np.quantile(all_x0, 0.75)\n",
    "    IQR_x0 = q3_x0 - q1_x0\n",
    "    \n",
    "    all_y0 = [b[1] for b in bboxes if not(b is None)]\n",
    "    median_y0 = np.median(all_y0)\n",
    "    q1_y0 = np.quantile(all_y0, 0.25)\n",
    "    q3_y0 = np.quantile(all_y0, 0.75)\n",
    "    IQR_y0 = q3_y0 - q1_y0\n",
    "    \n",
    "    out_bboxes = [None]*len(bboxes)\n",
    "    outliers = [None]*len(bboxes)\n",
    "    for i,b in enumerate(bboxes):\n",
    "        if not(b is None):\n",
    "            if (b[0]>=q1_x0-(1.5*IQR_x0)) and (b[0]<=q3_x0+(1.5*IQR_x0)) and \\\n",
    "            (b[1]>=q1_y0-(1.5*IQR_y0)) and (b[1]<=q3_y0+(1.5*IQR_y0)):\n",
    "                out_bboxes[i] = b[:]\n",
    "            else:\n",
    "                outliers[i] = b[:]\n",
    "                \n",
    "    print('usable bboxes:', len([b for b in out_bboxes if not(b is None)]))\n",
    "    print('outlier bboxes:', len([b for b in outliers if not(b is None)]))\n",
    "    \n",
    "    return out_bboxes\n",
    "\n",
    "\n",
    "\n",
    "def perform_MC(pickle_full_path, nifti_segmentation_path, mp4_path,\n",
    "              ROI_margin_suffix, frame_rate_suffix):\n",
    "    \n",
    "    if frame_rate_suffix == 'fullFrameRate':\n",
    "        step = 1\n",
    "    elif frame_rate_suffix == 'halfFrameRate':\n",
    "        step = 2\n",
    "    \n",
    "    full_array = load_pickle(pickle_full_path).astype(np.uint8)\n",
    "    \n",
    "    full_h = full_array.shape[1]\n",
    "    search_margin = int((0.5/15)*full_h)\n",
    "\n",
    "    ref_frames, bboxes, masks = find_ref_frames_from_nifti(nifti_segmentation_path, ROI_margin_suffix, search_margin)\n",
    "\n",
    "    #############################################################\n",
    "    #find initial correlation in the first run\n",
    "    min_x0 = min([e[0] for e in bboxes]) - search_margin\n",
    "    max_x1 = max([e[0]+e[2] for e in bboxes]) + search_margin\n",
    "    min_y0 = min([e[1] for e in bboxes]) - search_margin\n",
    "    max_y1 = max([e[1]+e[3] for e in bboxes]) + search_margin\n",
    "    bmode = full_array[:,\n",
    "                  min_y0:max_y1,\n",
    "                  min_x0:max_x1]\n",
    "    ref_bmodes = []\n",
    "    for ri in range(ref_frames.shape[0]):\n",
    "        ref_f = ref_frames[ri]\n",
    "        ref_b = bboxes[ri]\n",
    "        ref_bmodes.append(full_array[ref_f,\n",
    "                                    ref_b[1]:ref_b[1]+ref_b[3],\n",
    "                                    ref_b[0]:ref_b[0]+ref_b[2]])\n",
    "    corr_initial_run, threshold = find_correlation(bmode, ref_bmodes, set_quantile)\n",
    "    print('initial threshold:', threshold)\n",
    "    ############################################################\n",
    "    \n",
    "    ref_patches = ref_bmodes[:]\n",
    "    \n",
    "    previous_all_lesion_bboxes = [None]*full_array.shape[0]\n",
    "    iteration = 1\n",
    "        \n",
    "    while True:\n",
    "        \n",
    "        out_array = np.zeros(list(full_array.shape)+[3], dtype=np.uint8)\n",
    "        \n",
    "        all_search_bboxes = [None]*full_array.shape[0]\n",
    "        all_lesion_bboxes = [None]*full_array.shape[0]\n",
    "        corr_with_ref = [None]*full_array.shape[0]\n",
    "    \n",
    "        for ref_idx in range(ref_frames.shape[0]):\n",
    "            ref_frame = ref_frames[ref_idx]\n",
    "            ref_bbox = bboxes[ref_idx]\n",
    "\n",
    "            #show location of the ref_bbox\n",
    "            if iteration == 1 and ref_idx==0:\n",
    "                img_bbox = cv2.rectangle(cv2.cvtColor(full_array[ref_frame], cv2.COLOR_GRAY2BGR),\n",
    "                                             (ref_bbox[0], ref_bbox[1]),\n",
    "                                             (ref_bbox[0] + ref_bbox[2], ref_bbox[1] + ref_bbox[3]),\n",
    "                                             (0, 255, 0), 5)\n",
    "                plt.imshow(img_bbox)\n",
    "                plt.show()\n",
    "\n",
    "            #compute the temporal segment the ref_frame is responsible for\n",
    "            #######################\n",
    "            if ref_idx == 0:\n",
    "                if ref_idx == ref_frames.shape[0] - 1:\n",
    "                    #There is only 1 ref_frame\n",
    "                    ref_begin = 0\n",
    "                    ref_end = full_array.shape[0]\n",
    "                else:\n",
    "                    #This is the first ref_frame. There are >1 ref frames.\n",
    "                    ref_begin = 0\n",
    "                    ref_end = int((ref_frames[ref_idx]+ref_frames[ref_idx+1])/2)\n",
    "            else:\n",
    "                if ref_idx == ref_frames.shape[0] - 1:\n",
    "                    #This is the last ref frame. There are >1 ref frames.\n",
    "                    ref_begin = int((ref_frames[ref_idx-1]+ref_frames[ref_idx])/2)\n",
    "                    ref_end = full_array.shape[0]\n",
    "                else:\n",
    "                    #These are ref frames in the middle. There are >1 ref frames.\n",
    "                    ref_begin = int((ref_frames[ref_idx-1]+ref_frames[ref_idx])/2)\n",
    "                    ref_end = int((ref_frames[ref_idx]+ref_frames[ref_idx+1])/2)\n",
    "            #######################\n",
    "\n",
    "            #forward tracking\n",
    "            ##############################################################\n",
    "            if ref_frame < ref_end-1:  #can forward track only if there are frames after the ref_frame\n",
    "                previous_bbox = ref_bbox\n",
    "                valid = True\n",
    "\n",
    "                for frame in range(ref_frame, ref_end, step):\n",
    "\n",
    "                    full_frame = full_array[frame]\n",
    "\n",
    "                    if valid:\n",
    "                        search_w = int(previous_bbox[2]+(2*search_margin))\n",
    "                        search_h = int(previous_bbox[3]+(2*search_margin))\n",
    "                        search_x0 = int(previous_bbox[0] - ((search_w - previous_bbox[2])/2))\n",
    "                        search_y0 = int(previous_bbox[1] - ((search_h - previous_bbox[3])/2))\n",
    "                        search_bbox = (search_x0, search_y0, search_w, search_h)\n",
    "                        search_region = full_frame[search_y0:search_y0+search_h,\n",
    "                                                  search_x0:search_x0+search_w]\n",
    "\n",
    "                        all_search_bboxes[frame] = search_bbox\n",
    "\n",
    "                    else:\n",
    "                        all_search_x0 = [b[0] for b in all_search_bboxes[ref_frame+1:ref_end] if not(b is None)]\n",
    "                        median_x0 = np.median(all_search_x0)\n",
    "                        IQR_x0 = np.quantile(all_search_x0, 0.75) - np.quantile(all_search_x0, 0.25)\n",
    "                        all_search_x0 = [x for x in all_search_x0 if (x>=median_x0-(1.5*IQR_x0)) and (x<=median_x0+(1.5*IQR_x0))]\n",
    "                        min_search_x0 = min(all_search_x0)\n",
    "                        max_search_x0 = max(all_search_x0)\n",
    "\n",
    "                        all_search_y0 = [b[1] for b in all_search_bboxes[ref_frame+1:ref_end] if not(b is None)]\n",
    "                        median_y0 = np.median(all_search_y0)\n",
    "                        IQR_y0 = np.quantile(all_search_y0, 0.75) - np.quantile(all_search_y0, 0.25)\n",
    "                        all_search_y0 = [y for y in all_search_y0 if (y>=median_y0-(1.5*IQR_y0)) and (y<=median_y0+(1.5*IQR_y0))]\n",
    "                        min_search_y0 = min(all_search_y0)\n",
    "                        max_search_y0 = max(all_search_y0)\n",
    "\n",
    "                        search_x0 = min_search_x0\n",
    "                        search_y0 = min_search_y0\n",
    "                        search_w = (max_search_x0-min_search_x0) + int(ref_bbox[2]+(2*search_margin))\n",
    "                        search_h = (max_search_y0-min_search_y0) + int(previous_bbox[3]+(2*search_margin))\n",
    "                        search_bbox = (search_x0, search_y0, search_w, search_h)\n",
    "                        search_region = full_frame[search_y0:search_y0+search_h,\n",
    "                                                      search_x0:search_x0+search_w]    \n",
    "\n",
    "                    mean_corr, max_loc = compute_similarity_map(search_region, ref_patches, ref_idx)\n",
    "                    corr_with_ref[frame] = mean_corr\n",
    "                    \n",
    "                    if mean_corr >= threshold:\n",
    "                        valid = True\n",
    "                        current_w = ref_bbox[2]\n",
    "                        current_h = ref_bbox[3]\n",
    "                        current_x0 = search_x0 + max_loc[0]\n",
    "                        current_y0 = search_y0 + max_loc[1]\n",
    "                        current_bbox = (current_x0, current_y0, current_w, current_h)\n",
    "\n",
    "                        img_bbox = cv2.rectangle(cv2.cvtColor(full_frame, cv2.COLOR_GRAY2BGR),\n",
    "                                                     (search_x0, search_y0),\n",
    "                                                     (search_x0+search_w, search_y0+search_h),\n",
    "                                                     (255, 255, 255), 2)\n",
    "                        img_bbox = cv2.rectangle(img_bbox,\n",
    "                                                     (current_bbox[0], current_bbox[1]),\n",
    "                                                     (current_bbox[0] + current_bbox[2], current_bbox[1] + current_bbox[3]),\n",
    "                                                     (0, 255, 0), 2)\n",
    "                        img_bbox = cv2.putText(img_bbox, 'frame: '+str(frame), (25,25), cv2.FONT_HERSHEY_SIMPLEX,  \n",
    "                                       1, (0,255,0), 2, cv2.LINE_AA) \n",
    "                        img_bbox = cv2.putText(img_bbox, 'corr: '+str(mean_corr), (25,50), cv2.FONT_HERSHEY_SIMPLEX,  \n",
    "                                       1, (0,255,0), 2, cv2.LINE_AA) \n",
    "\n",
    "                        out_array[frame] = img_bbox\n",
    "\n",
    "                        all_lesion_bboxes[frame] = current_bbox[:]\n",
    "                        previous_bbox = current_bbox[:]\n",
    "                        \n",
    "                    else:\n",
    "                        valid = False\n",
    "                        img_bbox = cv2.rectangle(cv2.cvtColor(full_frame, cv2.COLOR_GRAY2BGR),\n",
    "                                                     (search_x0, search_y0),\n",
    "                                                     (search_x0+search_w, search_y0+search_h),\n",
    "                                                     (0, 0, 255), 2)\n",
    "                        img_bbox = cv2.putText(img_bbox, 'frame: '+str(frame), (25,25), cv2.FONT_HERSHEY_SIMPLEX,  \n",
    "                                       1, (0,0,255), 2, cv2.LINE_AA) \n",
    "                        img_bbox = cv2.putText(img_bbox, 'corr: '+str(mean_corr), (25,50), cv2.FONT_HERSHEY_SIMPLEX,  \n",
    "                                       1, (0,0,255), 2, cv2.LINE_AA) \n",
    "\n",
    "                        out_array[frame] = img_bbox\n",
    "            ##############################################################\n",
    "            \n",
    "            #backward tracking\n",
    "            ##############################################################\n",
    "            if ref_frame > ref_begin:  \n",
    "                previous_bbox = ref_bbox\n",
    "                valid = True\n",
    "\n",
    "                for frame in range(ref_frame-1, ref_begin-1, -step):\n",
    "\n",
    "                    full_frame = full_array[frame]\n",
    "\n",
    "                    if valid:\n",
    "                        search_w = int(previous_bbox[2]+(2*search_margin))\n",
    "                        search_h = int(previous_bbox[3]+(2*search_margin))\n",
    "                        search_x0 = int(previous_bbox[0] - ((search_w - previous_bbox[2])/2))\n",
    "                        search_y0 = int(previous_bbox[1] - ((search_h - previous_bbox[3])/2))\n",
    "                        search_bbox = (search_x0, search_y0, search_w, search_h)\n",
    "                        search_region = full_frame[search_y0:search_y0+search_h,\n",
    "                                                  search_x0:search_x0+search_w]\n",
    "\n",
    "                        all_search_bboxes[frame] = search_bbox\n",
    "\n",
    "                    else:\n",
    "                        all_search_x0 = [b[0] for b in all_search_bboxes[ref_begin:ref_frame] if not(b is None)]\n",
    "                        median_x0 = np.median(all_search_x0)\n",
    "                        IQR_x0 = np.quantile(all_search_x0, 0.75) - np.quantile(all_search_x0, 0.25)\n",
    "                        all_search_x0 = [x for x in all_search_x0 if (x>=median_x0-(1.5*IQR_x0)) and (x<=median_x0+(1.5*IQR_x0))]\n",
    "                        min_search_x0 = min(all_search_x0)\n",
    "                        max_search_x0 = max(all_search_x0)\n",
    "\n",
    "                        all_search_y0 = [b[1] for b in all_search_bboxes[ref_begin:ref_frame] if not(b is None)]\n",
    "                        median_y0 = np.median(all_search_y0)\n",
    "                        IQR_y0 = np.quantile(all_search_y0, 0.75) - np.quantile(all_search_y0, 0.25)\n",
    "                        all_search_y0 = [y for y in all_search_y0 if (y>=median_y0-(1.5*IQR_y0)) and (y<=median_y0+(1.5*IQR_y0))]\n",
    "                        min_search_y0 = min(all_search_y0)\n",
    "                        max_search_y0 = max(all_search_y0)\n",
    "\n",
    "                        search_x0 = min_search_x0\n",
    "                        search_y0 = min_search_y0\n",
    "                        search_w = (max_search_x0-min_search_x0) + int(ref_bbox[2]+(2*search_margin))\n",
    "                        search_h = (max_search_y0-min_search_y0) + int(previous_bbox[3]+(2*search_margin))\n",
    "                        search_bbox = (search_x0, search_y0, search_w, search_h)\n",
    "                        search_region = full_frame[search_y0:search_y0+search_h,\n",
    "                                                      search_x0:search_x0+search_w]    \n",
    "\n",
    "                    mean_corr, max_loc = compute_similarity_map(search_region, ref_patches, ref_idx)\n",
    "                    corr_with_ref[frame] = mean_corr\n",
    "                    \n",
    "                    if mean_corr >= threshold:\n",
    "                        valid = True\n",
    "                        current_w = ref_bbox[2]\n",
    "                        current_h = ref_bbox[3]\n",
    "                        current_x0 = search_x0 + max_loc[0]\n",
    "                        current_y0 = search_y0 + max_loc[1]\n",
    "                        current_bbox = (current_x0, current_y0, current_w, current_h)\n",
    "\n",
    "                        img_bbox = cv2.rectangle(cv2.cvtColor(full_frame, cv2.COLOR_GRAY2BGR),\n",
    "                                                     (search_x0, search_y0),\n",
    "                                                     (search_x0+search_w, search_y0+search_h),\n",
    "                                                     (255, 255, 255), 2)\n",
    "                        img_bbox = cv2.rectangle(img_bbox,\n",
    "                                                     (current_bbox[0], current_bbox[1]),\n",
    "                                                     (current_bbox[0] + current_bbox[2], current_bbox[1] + current_bbox[3]),\n",
    "                                                     (0, 255, 0), 2)\n",
    "                        img_bbox = cv2.putText(img_bbox, 'frame: '+str(frame), (25,25), cv2.FONT_HERSHEY_SIMPLEX,  \n",
    "                                       1, (0,255,0), 2, cv2.LINE_AA) \n",
    "                        img_bbox = cv2.putText(img_bbox, 'corr: '+str(mean_corr), (25,50), cv2.FONT_HERSHEY_SIMPLEX,  \n",
    "                                       1, (0,255,0), 2, cv2.LINE_AA) \n",
    "\n",
    "                        out_array[frame] = img_bbox\n",
    "\n",
    "                        all_lesion_bboxes[frame] = current_bbox[:]\n",
    "                        previous_bbox = current_bbox[:]\n",
    "                        \n",
    "                    else:\n",
    "                        valid = False\n",
    "                        img_bbox = cv2.rectangle(cv2.cvtColor(full_frame, cv2.COLOR_GRAY2BGR),\n",
    "                                                     (search_x0, search_y0),\n",
    "                                                     (search_x0+search_w, search_y0+search_h),\n",
    "                                                     (0, 0, 255), 2)\n",
    "                        img_bbox = cv2.putText(img_bbox, 'frame: '+str(frame), (25,25), cv2.FONT_HERSHEY_SIMPLEX,  \n",
    "                                       1, (0,0,255), 2, cv2.LINE_AA) \n",
    "                        img_bbox = cv2.putText(img_bbox, 'corr: '+str(mean_corr), (25,50), cv2.FONT_HERSHEY_SIMPLEX,  \n",
    "                                       1, (0,0,255), 2, cv2.LINE_AA) \n",
    "\n",
    "                        out_array[frame] = img_bbox\n",
    "            ##############################################################\n",
    "            \n",
    "\n",
    "        #check if lesion bbox in any frame move in this iteration\n",
    "        #####################\n",
    "        bbox_move = check_bbox_move(previous_all_lesion_bboxes, all_lesion_bboxes)\n",
    "        if bbox_move or (threshold < min([e for e in corr_with_ref if not(e is None)])):\n",
    "            break\n",
    "        #####################\n",
    "\n",
    "        previous_threshold = threshold\n",
    "        previous_all_lesion_bboxes = all_lesion_bboxes[:]\n",
    "        previous_out_array = out_array.copy()\n",
    "        previous_corr_with_ref = corr_with_ref.copy()\n",
    "        threshold -= threshold_decrease_per_step\n",
    "        iteration += 1\n",
    "     \n",
    "    print('iteration:', iteration-1)\n",
    "    print('threshold:', previous_threshold)\n",
    "\n",
    "    out_array = previous_out_array.copy()\n",
    "   \n",
    "    export_video(out_array, mp4_path, CineRate=10)\n",
    "    \n",
    "    return full_array, previous_all_lesion_bboxes, ref_frames, bboxes, masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for ROI_margin_suffix in ROI_margin_suffix_list:\n",
    "    for frame_rate_suffix in frame_rate_suffix_list:\n",
    "        \n",
    "        export_dir = export_dir_prefix + ROI_margin_suffix + '_' + frame_rate_suffix\n",
    "        \n",
    "        df = pd.read_excel(dataset_path, dtype=str)\n",
    "        print(df.shape)\n",
    "        \n",
    "        for col in df.columns:\n",
    "            if col.endswith('_path'):\n",
    "                df.loc[:,col] = df[col].apply(add_data_dir, args=(data_dir,))\n",
    "                \n",
    "        for row_idx in tqdm(df.index):\n",
    "            patient_code_inj = df.loc[row_idx, 'patient_code_inj']\n",
    "            print(patient_code_inj)\n",
    "            pickle_full_path = df.loc[row_idx, 'pickle_bmode_CE_gray_path']\n",
    "            print(pickle_full_path)\n",
    "            mp4_path = join(export_mp4_dir, patient_code_inj+'.mp4')\n",
    "            nifti_segmentation_path = df.loc[row_idx, 'nifti_segmentation_path']\n",
    "\n",
    "            full_array, bmode_MC_bboxes, ref_frames, ref_bboxes, ref_masks = perform_MC(pickle_full_path, \n",
    "                                                                                        nifti_segmentation_path, \n",
    "                                                                                        mp4_path,\n",
    "                                                                                        ROI_margin_suffix, \n",
    "                                                                                        frame_rate_suffix)\n",
    "\n",
    "            #resize all MC bboxes to the same size\n",
    "            bmode_MC_bboxes = resize_MC_bboxes(bmode_MC_bboxes)\n",
    "\n",
    "            #remove outlier bboxes\n",
    "            bmode_MC_bboxes = remove_outlier_bboxes(bmode_MC_bboxes, full_array)\n",
    "\n",
    "            n_frames = full_array.shape[0]\n",
    "\n",
    "            x0_bmode = int(df.loc[row_idx, 'x0_bmode'])\n",
    "            y0_bmode = int(df.loc[row_idx, 'y0_bmode'])\n",
    "            w_bmode = int(df.loc[row_idx, 'w_bmode'])\n",
    "            h_bmode = int(df.loc[row_idx, 'h_bmode'])\n",
    "            x0_CE = int(df.loc[row_idx, 'x0_CE'])\n",
    "            y0_CE = int(df.loc[row_idx, 'y0_CE'])\n",
    "            w_CE = int(df.loc[row_idx, 'w_CE'])\n",
    "            h_CE = int(df.loc[row_idx, 'h_CE'])\n",
    "            CE_side = df.loc[row_idx, 'CE_window_left(l)_or_right(r)']\n",
    "\n",
    "            CE_MC_bboxes = create_CE_MC_bboxes(bmode_MC_bboxes, x0_bmode, x0_CE, CE_side)\n",
    "            bmode_ori_bboxes = create_ori_bboxes(ref_frames, ref_bboxes, n_frames).astype('int')\n",
    "            CE_ori_bboxes = create_CE_ori_bboxes(bmode_ori_bboxes, x0_bmode, x0_CE, CE_side).astype('int')\n",
    "\n",
    "            #cut ROI\n",
    "            if not fixed_size_ROI:\n",
    "                #use \"cut_ROI\" function to get ROI exactly fit to the lesion\n",
    "                bmode_ori_ROI = cut_ROI(full_array, bmode_ori_bboxes)\n",
    "                CE_ori_ROI = cut_ROI(full_array, CE_ori_bboxes)\n",
    "                bmode_MC_ROI = cut_ROI(full_array, bmode_MC_bboxes)\n",
    "                CE_MC_ROI = cut_ROI(full_array, CE_MC_bboxes)\n",
    "                seg_masks = create_segmentation_masks(ref_frames, ref_masks, n_frames)\n",
    "            else:\n",
    "                #use \"cut_ROI200\" function to get a fixed size ROI\n",
    "                bmode_ori_ROI = cut_ROI200(full_array, bmode_ori_bboxes, (x0_bmode,y0_bmode,w_bmode,h_bmode))\n",
    "                CE_ori_ROI = cut_ROI200(full_array, CE_ori_bboxes, (x0_CE,y0_CE,w_CE,h_CE))\n",
    "                bmode_MC_ROI = cut_ROI200(full_array, bmode_MC_bboxes, (x0_bmode,y0_bmode,w_bmode,h_bmode))\n",
    "                CE_MC_ROI = cut_ROI200(full_array, CE_MC_bboxes, (x0_CE,y0_CE,w_CE,h_CE))\n",
    "                seg_masks = create_segmentation_masks200(ref_frames, ref_masks, n_frames, CE_MC_ROI.shape[2], CE_MC_ROI.shape[1])\n",
    "\n",
    "            bmode_MC_ROI_pickle_path = pickle_full_path.replace(\n",
    "                '/pickle_bmode_CE_gray/', '/bmode_MC_ROI_pickle/').replace(\n",
    "                '/data/', '/outputs/motion-compensation/')\n",
    "            export_pickle(bmode_MC_ROI, bmode_MC_ROI_pickle_path)\n",
    "            df.loc[row_idx, 'bmode_MC_ROI_pickle_path'] = bmode_MC_ROI_pickle_path\n",
    "\n",
    "            CE_MC_ROI_pickle_path = pickle_full_path.replace(\n",
    "                '/pickle_bmode_CE_gray/', '/CE_MC_ROI_pickle/').replace(\n",
    "                '/data/', '/outputs/motion-compensation/')\n",
    "            export_pickle(CE_MC_ROI, CE_MC_ROI_pickle_path)\n",
    "            df.loc[row_idx, 'CE_MC_ROI_pickle_path'] = CE_MC_ROI_pickle_path\n",
    "\n",
    "            ROI_w = CE_MC_ROI.shape[2]\n",
    "            ROI_h = CE_MC_ROI.shape[1]\n",
    "            df.loc[row_idx, 'MC_ROI_w'] = ROI_w\n",
    "            df.loc[row_idx, 'MC_ROI_h'] = ROI_h\n",
    "\n",
    "            export_pickle(bmode_ori_ROI, join(export_dir, patient_code_inj, 'bmode_ori_ROI.pkl'))\n",
    "            export_pickle(CE_ori_ROI, join(export_dir, patient_code_inj, 'CE_ori_ROI.pkl'))\n",
    "            export_pickle(bmode_MC_ROI, join(export_dir, patient_code_inj, 'bmode_MC_ROI.pkl'))\n",
    "            export_pickle(CE_MC_ROI, join(export_dir, patient_code_inj, 'CE_MC_ROI.pkl'))\n",
    "            export_pickle(seg_masks, join(export_dir, patient_code_inj, 'seg_masks.pkl'))\n",
    "            \n",
    "df.to_excel(export_excel_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-11.m91",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-11:m91"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from os.path import join, isfile, exists, isdir, dirname\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '../sample-data/dataset_synthesize.xlsx'\n",
    "data_dir = '../sample-data'\n",
    "\n",
    "export_dir_prefix = '../outputs/'\n",
    "export_excel_path = '../outputs/motion-compensation.xlsx'\n",
    "export_mp4_dir = '../outputs/mp4-outputs'\n",
    "\n",
    "ROI_margin_suffix_list = ['withoutROImargin']  #['withROImargin', 'withoutROImargin']\n",
    "frame_rate_suffix_list = ['fullFrameRate']  #['halfFrameRate', 'fullFrameRate']\n",
    "\n",
    "fixed_size_ROI = False  #if True, the output ROIs will have a fixed size, rather than fitted to the lesion\n",
    "\n",
    "set_quantile = 0.50  #initial quantile\n",
    "threshold_decrease_per_step = 0.02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_data_dir(x, data_dir):\n",
    "    if pd.isna(x):\n",
    "        return None\n",
    "    else:\n",
    "        return join(data_dir, x)\n",
    "\n",
    "\n",
    "\n",
    "def load_pickle(pickle_path):\n",
    "    with open(pickle_path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    print(data.shape)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "def find_ref_frames_from_nifti(nifti_path, ROI_margin_suffix, search_margin):\n",
    "    \n",
    "    nifti_array = np.transpose(nib.load(nifti_path).get_fdata()).astype(int)\n",
    "    print(nifti_array.shape)  # expected (frames, height, width)\n",
    "\n",
    "    spatial_sum = np.sum(nifti_array, axis=(1, 2))  # shape (frames,)\n",
    "    ref_frames = np.argwhere(spatial_sum > 0)\n",
    "    ref_frames = np.reshape(ref_frames, ref_frames.shape[0])\n",
    "\n",
    "    if ROI_margin_suffix == 'withROImargin':\n",
    "        ROI_margin = int(search_margin/2)\n",
    "    elif ROI_margin_suffix == 'withoutROImargin':\n",
    "        ROI_margin = 0\n",
    "    \n",
    "    bboxes = []\n",
    "    masks = []\n",
    "    for i,ref_frame in enumerate(ref_frames):\n",
    "        mask = nifti_array[ref_frame]\n",
    "        pos_coor = np.argwhere(mask > 0)\n",
    "        x_values = pos_coor[:, 1]\n",
    "        y_values = pos_coor[:, 0]\n",
    "        x0 = x_values.min()\n",
    "        x1 = x_values.max()\n",
    "        w = x1 - x0 + 1\n",
    "        y0 = y_values.min()\n",
    "        y1 = y_values.max()\n",
    "        h = y1 - y0 + 1\n",
    "        \n",
    "        bboxes.append((x0-ROI_margin,\n",
    "                       y0-ROI_margin,\n",
    "                       w+(2*ROI_margin),\n",
    "                       h+(2*ROI_margin)))\n",
    "        masks.append(mask[y0-ROI_margin:y0-ROI_margin+h+(2*ROI_margin), \n",
    "                          x0-ROI_margin:x0-ROI_margin+w+(2*ROI_margin)])\n",
    "\n",
    "    return ref_frames, bboxes, masks\n",
    "\n",
    "\n",
    "\n",
    "def export_video(cine_array, mp4_path, CineRate):\n",
    "\n",
    "    mp4_dir = dirname(mp4_path)\n",
    "    if not exists(mp4_dir):\n",
    "        os.makedirs(mp4_dir)\n",
    "\n",
    "    width = cine_array.shape[2]\n",
    "    height = cine_array.shape[1]\n",
    "    if pd.notna(CineRate):\n",
    "        frame_rate = int(CineRate)\n",
    "    else:\n",
    "        print('no CineRate in excel file; using default frame rate = 9')\n",
    "        frame_rate = 9\n",
    "\n",
    "    writer = cv2.VideoWriter(mp4_path, cv2.VideoWriter_fourcc(*'XVID'), frame_rate, (width, height))\n",
    "\n",
    "    if len(cine_array.shape) == 3:  # grayscale\n",
    "        for frame in range(cine_array.shape[0]):\n",
    "            writer.write(cv2.cvtColor(cine_array[frame], cv2.COLOR_GRAY2BGR))\n",
    "    elif len(cine_array.shape) == 4:  # RGB\n",
    "        for frame in range(cine_array.shape[0]):\n",
    "            writer.write(cine_array[frame])\n",
    "    else:\n",
    "        print('color channel not compatible for video exporting; please check dimension of array.')\n",
    "\n",
    "    writer.release()\n",
    "    \n",
    "    \n",
    "    \n",
    "def apply_blur(cine_array):\n",
    "    out = np.zeros(cine_array.shape)\n",
    "    for frame in range(cine_array.shape[0]):\n",
    "        img = cine_array[frame]\n",
    "        img = cv2.GaussianBlur(img, (21, 21), 0)\n",
    "        out[frame] = img\n",
    "    out = out.astype(np.uint8)\n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "def plot_correlation(corr_with_ref, threshold):\n",
    "    plt.figure(figsize=(24,6))\n",
    "    plt.axhline(threshold, color='b')\n",
    "    plt.plot(range(len(corr_with_ref)), corr_with_ref, marker='o', color='g', label='corr_with_ref')\n",
    "    plt.ylim(0,1.0)\n",
    "    plt.ylabel('corr_coef')\n",
    "    plt.xlabel('frame')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "def find_correlation(bmode, ref_bmodes, set_quantile):\n",
    "    \n",
    "    n_refs = len(ref_bmodes)\n",
    "    n_frames = bmode.shape[0]\n",
    "    correlations = np.zeros((n_refs, n_frames))\n",
    "    \n",
    "    for ref_idx in range(n_refs):\n",
    "        ref = ref_bmodes[ref_idx]\n",
    "        for frame in range(n_frames):\n",
    "            similarity_map = cv2.matchTemplate(bmode[frame], ref, cv2.TM_CCOEFF_NORMED)\n",
    "            min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(similarity_map)\n",
    "            correlations[ref_idx, frame] = max_val\n",
    "            \n",
    "    correlations = np.mean(correlations, axis=0)\n",
    "    threshold = np.quantile(correlations, set_quantile)\n",
    "    \n",
    "    return correlations, threshold\n",
    "\n",
    "\n",
    "\n",
    "def check_bbox_move(previous_all_lesion_bboxes, all_lesion_bboxes):\n",
    "    \n",
    "    bbox_move = False\n",
    "    \n",
    "    for frame in range(len(previous_all_lesion_bboxes)):\n",
    "        previous_bbox = previous_all_lesion_bboxes[frame]\n",
    "        current_bbox = all_lesion_bboxes[frame]\n",
    "        if not(previous_bbox is None):\n",
    "            if not(previous_bbox == current_bbox):\n",
    "                bbox_move = True\n",
    "                break\n",
    "    \n",
    "    return bbox_move\n",
    "\n",
    "\n",
    "\n",
    "def compute_similarity_map(search_region, ref_patches, current_ref_idx):\n",
    "    \n",
    "    n_refs = len(ref_patches)\n",
    "    corrs = np.zeros((n_refs,))\n",
    "    \n",
    "    for ref_idx in range(n_refs):\n",
    "        ref = ref_patches[ref_idx]\n",
    "        similarity_map = cv2.matchTemplate(search_region, ref, cv2.TM_CCOEFF_NORMED)\n",
    "        min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(similarity_map)\n",
    "        corrs[ref_idx] = max_val\n",
    "        if current_ref_idx == ref_idx:\n",
    "            current_max_loc = max_loc\n",
    "            \n",
    "    mean_corr = np.mean(corrs)\n",
    "            \n",
    "    return mean_corr, current_max_loc\n",
    "\n",
    "\n",
    "\n",
    "def resize_MC_bboxes(bboxes):\n",
    "    #resize bboxes to minimum width and height\n",
    "    \n",
    "    min_w = min([b[2] for b in bboxes if not(b is None)])\n",
    "    min_h = min([b[3] for b in bboxes if not(b is None)])\n",
    "    \n",
    "    for i in range(len(bboxes)):\n",
    "        if bboxes[i] is None:\n",
    "            continue\n",
    "        x0, y0, w, h = bboxes[i]\n",
    "        new_w = min_w\n",
    "        new_h = min_h\n",
    "        new_x0 = x0 + int((w-new_w)/2)\n",
    "        new_y0 = y0 + int((h-new_h)/2)\n",
    "        bboxes[i] = (new_x0, new_y0, new_w, new_h)\n",
    "        \n",
    "    return bboxes\n",
    "\n",
    "\n",
    "\n",
    "def create_CE_MC_bboxes(bmode_bboxes, x0_bmode, x0_CE, CE_side):\n",
    "    \n",
    "    CE_bboxes = [None] * len(bmode_bboxes)\n",
    "    \n",
    "    for i in range(len(bmode_bboxes)):\n",
    "        if bmode_bboxes[i] is None:\n",
    "            continue\n",
    "        x0, y0, w, h = bmode_bboxes[i]\n",
    "        \n",
    "        if CE_side == 'r':\n",
    "            new_x0 = x0 + (x0_CE-x0_bmode)\n",
    "        elif CE_side == 'l':\n",
    "            new_x0 = x0 - (x0_bmode-x0_CE)\n",
    "        else:\n",
    "            raise Exception('Error in create_CE_MC_bboxes')\n",
    "            \n",
    "        CE_bboxes[i] = (new_x0, y0, w, h)\n",
    "    \n",
    "    return CE_bboxes\n",
    "\n",
    "\n",
    "\n",
    "def create_segmentation_masks(ref_frames, ref_masks, n_frames):\n",
    "    \n",
    "    min_h = min([m.shape[0] for m in ref_masks])\n",
    "    min_w = min([m.shape[1] for m in ref_masks])\n",
    "    \n",
    "    seg_masks = np.zeros((n_frames, min_h, min_w))\n",
    "    \n",
    "    for ref_idx in range(ref_frames.shape[0]):\n",
    "        ref_frame = ref_frames[ref_idx]\n",
    "        \n",
    "        #compute the temporal segment the ref_frame is responsible for\n",
    "        if ref_idx == 0:\n",
    "            if ref_idx == ref_frames.shape[0] - 1:\n",
    "                #There is only 1 ref_frame\n",
    "                ref_begin = 0\n",
    "                ref_end = n_frames\n",
    "            else:\n",
    "                #This is the first ref_frame. There are >1 ref frames.\n",
    "                ref_begin = 0\n",
    "                ref_end = int((ref_frames[ref_idx]+ref_frames[ref_idx+1])/2)\n",
    "        else:\n",
    "            if ref_idx == ref_frames.shape[0] - 1:\n",
    "                #This is the last ref frame. There are >1 ref frames.\n",
    "                ref_begin = int((ref_frames[ref_idx-1]+ref_frames[ref_idx])/2)\n",
    "                ref_end = n_frames\n",
    "            else:\n",
    "                #These are ref frames in the middle. There are >1 ref frames.\n",
    "                ref_begin = int((ref_frames[ref_idx-1]+ref_frames[ref_idx])/2)\n",
    "                ref_end = int((ref_frames[ref_idx]+ref_frames[ref_idx+1])/2)\n",
    "        \n",
    "        ref_mask = ref_masks[ref_idx]\n",
    "        h = ref_mask.shape[0]\n",
    "        w = ref_mask.shape[1]\n",
    "        x0 = int((w-min_w)/2)\n",
    "        y0 = int((h-min_h)/2)\n",
    "        \n",
    "        seg_masks[ref_begin:ref_end] = ref_mask[y0:y0+min_h, x0:x0+min_w]   #broadcast\n",
    "        \n",
    "    return seg_masks\n",
    "\n",
    "\n",
    "\n",
    "def create_segmentation_masks200(ref_frames, ref_masks, n_frames, ROI_w, ROI_h):\n",
    "    \n",
    "    min_h = min([m.shape[0] for m in ref_masks])\n",
    "    min_w = min([m.shape[1] for m in ref_masks])\n",
    "    \n",
    "    seg_masks = np.zeros((n_frames, ROI_h, ROI_w))\n",
    "    \n",
    "    for ref_idx in range(ref_frames.shape[0]):\n",
    "        ref_frame = ref_frames[ref_idx]\n",
    "        \n",
    "        #compute the temporal segment the ref_frame is responsible for\n",
    "        if ref_idx == 0:\n",
    "            if ref_idx == ref_frames.shape[0] - 1:\n",
    "                #There is only 1 ref_frame\n",
    "                ref_begin = 0\n",
    "                ref_end = n_frames\n",
    "            else:\n",
    "                #This is the first ref_frame. There are >1 ref frames.\n",
    "                ref_begin = 0\n",
    "                ref_end = int((ref_frames[ref_idx]+ref_frames[ref_idx+1])/2)\n",
    "        else:\n",
    "            if ref_idx == ref_frames.shape[0] - 1:\n",
    "                #This is the last ref frame. There are >1 ref frames.\n",
    "                ref_begin = int((ref_frames[ref_idx-1]+ref_frames[ref_idx])/2)\n",
    "                ref_end = n_frames\n",
    "            else:\n",
    "                #These are ref frames in the middle. There are >1 ref frames.\n",
    "                ref_begin = int((ref_frames[ref_idx-1]+ref_frames[ref_idx])/2)\n",
    "                ref_end = int((ref_frames[ref_idx]+ref_frames[ref_idx+1])/2)\n",
    "        \n",
    "        ref_mask = ref_masks[ref_idx]\n",
    "        h = ref_mask.shape[0]\n",
    "        w = ref_mask.shape[1]\n",
    "        x0 = int((w-min_w)/2)\n",
    "        y0 = int((h-min_h)/2)\n",
    "        \n",
    "        top_offset = int((ROI_h-min_h)/2)\n",
    "        left_offset = int((ROI_w-min_w)/2)\n",
    "        seg_masks[ref_begin:ref_end, top_offset:top_offset+min_h, left_offset:left_offset+min_w] = ref_mask[y0:y0+min_h, x0:x0+min_w]   #broadcast\n",
    "        \n",
    "    return seg_masks\n",
    "\n",
    "\n",
    "\n",
    "def create_ori_bboxes(ref_frames, ref_bboxes, n_frames):\n",
    "    min_h = min([b[3] for b in ref_bboxes])\n",
    "    min_w = min([b[2] for b in ref_bboxes])\n",
    "    \n",
    "    ori_bboxes = np.zeros((n_frames, 4))\n",
    "    \n",
    "    for ref_idx in range(ref_frames.shape[0]):\n",
    "        ref_frame = ref_frames[ref_idx]\n",
    "        \n",
    "        #compute the temporal segment the ref_frame is responsible for\n",
    "        if ref_idx == 0:\n",
    "            if ref_idx == ref_frames.shape[0] - 1:\n",
    "                #There is only 1 ref_frame\n",
    "                ref_begin = 0\n",
    "                ref_end = n_frames\n",
    "            else:\n",
    "                #This is the first ref_frame. There are >1 ref frames.\n",
    "                ref_begin = 0\n",
    "                ref_end = int((ref_frames[ref_idx]+ref_frames[ref_idx+1])/2)\n",
    "        else:\n",
    "            if ref_idx == ref_frames.shape[0] - 1:\n",
    "                #This is the last ref frame. There are >1 ref frames.\n",
    "                ref_begin = int((ref_frames[ref_idx-1]+ref_frames[ref_idx])/2)\n",
    "                ref_end = n_frames\n",
    "            else:\n",
    "                #These are ref frames in the middle. There are >1 ref frames.\n",
    "                ref_begin = int((ref_frames[ref_idx-1]+ref_frames[ref_idx])/2)\n",
    "                ref_end = int((ref_frames[ref_idx]+ref_frames[ref_idx+1])/2)\n",
    "        \n",
    "        x0,y0,w,h = ref_bboxes[ref_idx]\n",
    "        new_w = min_w\n",
    "        new_h = min_h\n",
    "        new_x0 = x0 + int((w-new_w)/2)\n",
    "        new_y0 = y0 + int((h-new_h)/2)\n",
    "        \n",
    "        new_bbox = np.array([new_x0, new_y0, new_w, new_h])\n",
    "        \n",
    "        ori_bboxes[ref_begin:ref_end] = new_bbox   #broadcast\n",
    "        \n",
    "    return ori_bboxes\n",
    "\n",
    "\n",
    "\n",
    "def create_CE_ori_bboxes(bmode_bboxes, x0_bmode, x0_CE, CE_side):\n",
    "    CE_bboxes = bmode_bboxes.copy()\n",
    "        \n",
    "    if CE_side == 'r':\n",
    "        CE_bboxes[:,0] = CE_bboxes[:,0] + (x0_CE-x0_bmode)\n",
    "    elif CE_side == 'l':\n",
    "        CE_bboxes[:,0] = CE_bboxes[:,0] - (x0_bmode-x0_CE)\n",
    "    else:\n",
    "        raise Exception('Error in create_CE_ori_bboxes')\n",
    "            \n",
    "    return CE_bboxes\n",
    "\n",
    "\n",
    "\n",
    "def cut_ROI(full_array, bboxes):\n",
    "    \n",
    "    min_w = min([b[2] for b in bboxes if not(b is None)])\n",
    "    min_h = min([b[3] for b in bboxes if not(b is None)])\n",
    "    \n",
    "    ROI = np.zeros((full_array.shape[0], min_h, min_w))\n",
    "    \n",
    "    for frame in range(full_array.shape[0]):\n",
    "        bbox = bboxes[frame]\n",
    "        if bbox is None:  #skip MC frames without bbox (due to out-of-frame motion)\n",
    "            continue\n",
    "        x0,y0,w,h = bbox\n",
    "        ROI[frame] = full_array[frame, y0:y0+h, x0:x0+w]\n",
    "    \n",
    "    return ROI\n",
    "\n",
    "\n",
    "\n",
    "def cut_ROI200(full_array, bboxes, window_loc):\n",
    "    \n",
    "    min_w = min([b[2] for b in bboxes if not(b is None)])\n",
    "    min_h = min([b[3] for b in bboxes if not(b is None)])\n",
    "    \n",
    "    window_x0, window_y0, window_w, window_h = window_loc\n",
    "    \n",
    "    cut_h = int(max(0.4*window_h, min_h, min_w))\n",
    "    cut_w = cut_h\n",
    "    \n",
    "    ROI = np.zeros((full_array.shape[0], cut_h, cut_w))\n",
    "    \n",
    "    for frame in range(full_array.shape[0]):\n",
    "        bbox = bboxes[frame]\n",
    "        if bbox is None:  #skip MC frames without bbox (due to out-of-frame motion)\n",
    "            continue\n",
    "        x0,y0,w,h = bbox\n",
    "        x_center = x0 + int(w/2)\n",
    "        y_center = y0 + int(h/2)\n",
    "        valid_w = min(int(x_center+cut_w/2),window_x0+window_w) - max(int(x_center-cut_w/2),window_x0)\n",
    "        valid_h = min(int(y_center+cut_h/2),window_y0+window_h) - max(int(y_center-cut_h/2),window_y0)\n",
    "        center_ROI = int(cut_h/2)\n",
    "        ROI[frame, int(center_ROI-valid_h/2):int(center_ROI+valid_h/2), int(center_ROI-valid_w/2):int(center_ROI+valid_w/2)] = full_array[frame, \n",
    "                                max(int(y_center-cut_h/2),window_y0):min(int(y_center+cut_h/2),window_y0+window_h), \n",
    "                                max(int(x_center-cut_w/2),window_x0):min(int(x_center+cut_w/2),window_x0+window_w)]\n",
    "    \n",
    "    return ROI\n",
    "\n",
    "\n",
    "\n",
    "def visualize_ROI(bmode_ori_ROI, CE_ori_ROI, bmode_MC_ROI, CE_MC_ROI, seg_masks):\n",
    "    n_frames = bmode_ori_ROI.shape[0]\n",
    "    \n",
    "    for frame in range(min(n_frames,100)):\n",
    "        print('frame:', frame)\n",
    "        plt.figure()\n",
    "        plt.subplot(1,5,1)\n",
    "        plt.imshow(bmode_ori_ROI[frame], cmap='gray')\n",
    "        plt.subplot(1,5,2)\n",
    "        plt.imshow(CE_ori_ROI[frame], cmap='gray')\n",
    "        plt.subplot(1,5,3)\n",
    "        plt.imshow(bmode_MC_ROI[frame], cmap='gray')\n",
    "        plt.subplot(1,5,4)\n",
    "        plt.imshow(CE_MC_ROI[frame], cmap='gray')\n",
    "        plt.subplot(1,5,5)\n",
    "        plt.imshow(seg_masks[frame], cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "        \n",
    "def export_pickle(cine_array, pickle_path):\n",
    "    \n",
    "    pickle_dir = dirname(pickle_path)\n",
    "    if not exists(pickle_dir):\n",
    "        os.makedirs(pickle_dir)\n",
    "\n",
    "    with open(pickle_path, 'wb') as wr:\n",
    "        pickle.dump(cine_array, wr, protocol=4)\n",
    "        \n",
    "        \n",
    "        \n",
    "def remove_outlier_bboxes(bboxes, full_array):\n",
    "    \n",
    "    all_x0 = [b[0] for b in bboxes if not(b is None)]\n",
    "    median_x0 = np.median(all_x0)\n",
    "    q1_x0 = np.quantile(all_x0, 0.25)\n",
    "    q3_x0 = np.quantile(all_x0, 0.75)\n",
    "    IQR_x0 = q3_x0 - q1_x0\n",
    "    \n",
    "    all_y0 = [b[1] for b in bboxes if not(b is None)]\n",
    "    median_y0 = np.median(all_y0)\n",
    "    q1_y0 = np.quantile(all_y0, 0.25)\n",
    "    q3_y0 = np.quantile(all_y0, 0.75)\n",
    "    IQR_y0 = q3_y0 - q1_y0\n",
    "    \n",
    "    out_bboxes = [None]*len(bboxes)\n",
    "    outliers = [None]*len(bboxes)\n",
    "    for i,b in enumerate(bboxes):\n",
    "        if not(b is None):\n",
    "            if (b[0]>=q1_x0-(1.5*IQR_x0)) and (b[0]<=q3_x0+(1.5*IQR_x0)) and \\\n",
    "            (b[1]>=q1_y0-(1.5*IQR_y0)) and (b[1]<=q3_y0+(1.5*IQR_y0)):\n",
    "                out_bboxes[i] = b[:]\n",
    "            else:\n",
    "                outliers[i] = b[:]\n",
    "                \n",
    "    print('usable bboxes:', len([b for b in out_bboxes if not(b is None)]))\n",
    "    print('outlier bboxes:', len([b for b in outliers if not(b is None)]))\n",
    "    \n",
    "    return out_bboxes\n",
    "\n",
    "\n",
    "\n",
    "def perform_MC(pickle_full_path, nifti_segmentation_path, mp4_path,\n",
    "              ROI_margin_suffix, frame_rate_suffix):\n",
    "    \n",
    "    if frame_rate_suffix == 'fullFrameRate':\n",
    "        step = 1\n",
    "    elif frame_rate_suffix == 'halfFrameRate':\n",
    "        step = 2\n",
    "    \n",
    "    full_array = load_pickle(pickle_full_path).astype(np.uint8)\n",
    "    \n",
    "    full_h = full_array.shape[1]\n",
    "    search_margin = int((0.5/15)*full_h)\n",
    "\n",
    "    ref_frames, bboxes, masks = find_ref_frames_from_nifti(nifti_segmentation_path, ROI_margin_suffix, search_margin)\n",
    "\n",
    "    #############################################################\n",
    "    #find initial correlation in the first run\n",
    "    min_x0 = min([e[0] for e in bboxes]) - search_margin\n",
    "    max_x1 = max([e[0]+e[2] for e in bboxes]) + search_margin\n",
    "    min_y0 = min([e[1] for e in bboxes]) - search_margin\n",
    "    max_y1 = max([e[1]+e[3] for e in bboxes]) + search_margin\n",
    "    bmode = full_array[:,\n",
    "                  min_y0:max_y1,\n",
    "                  min_x0:max_x1]\n",
    "    ref_bmodes = []\n",
    "    for ri in range(ref_frames.shape[0]):\n",
    "        ref_f = ref_frames[ri]\n",
    "        ref_b = bboxes[ri]\n",
    "        ref_bmodes.append(full_array[ref_f,\n",
    "                                    ref_b[1]:ref_b[1]+ref_b[3],\n",
    "                                    ref_b[0]:ref_b[0]+ref_b[2]])\n",
    "    corr_initial_run, threshold = find_correlation(bmode, ref_bmodes, set_quantile)\n",
    "    print('initial threshold:', threshold)\n",
    "    ############################################################\n",
    "    \n",
    "    ref_patches = ref_bmodes[:]\n",
    "    \n",
    "    previous_all_lesion_bboxes = [None]*full_array.shape[0]\n",
    "    iteration = 1\n",
    "        \n",
    "    while True:\n",
    "        \n",
    "        out_array = np.zeros(list(full_array.shape)+[3], dtype=np.uint8)\n",
    "        \n",
    "        all_search_bboxes = [None]*full_array.shape[0]\n",
    "        all_lesion_bboxes = [None]*full_array.shape[0]\n",
    "        corr_with_ref = [None]*full_array.shape[0]\n",
    "    \n",
    "        for ref_idx in range(ref_frames.shape[0]):\n",
    "            ref_frame = ref_frames[ref_idx]\n",
    "            ref_bbox = bboxes[ref_idx]\n",
    "\n",
    "            #show location of the ref_bbox\n",
    "            if iteration == 1 and ref_idx==0:\n",
    "                img_bbox = cv2.rectangle(cv2.cvtColor(full_array[ref_frame], cv2.COLOR_GRAY2BGR),\n",
    "                                             (ref_bbox[0], ref_bbox[1]),\n",
    "                                             (ref_bbox[0] + ref_bbox[2], ref_bbox[1] + ref_bbox[3]),\n",
    "                                             (0, 255, 0), 5)\n",
    "                plt.imshow(img_bbox)\n",
    "                plt.show()\n",
    "\n",
    "            #compute the temporal segment the ref_frame is responsible for\n",
    "            #######################\n",
    "            if ref_idx == 0:\n",
    "                if ref_idx == ref_frames.shape[0] - 1:\n",
    "                    #There is only 1 ref_frame\n",
    "                    ref_begin = 0\n",
    "                    ref_end = full_array.shape[0]\n",
    "                else:\n",
    "                    #This is the first ref_frame. There are >1 ref frames.\n",
    "                    ref_begin = 0\n",
    "                    ref_end = int((ref_frames[ref_idx]+ref_frames[ref_idx+1])/2)\n",
    "            else:\n",
    "                if ref_idx == ref_frames.shape[0] - 1:\n",
    "                    #This is the last ref frame. There are >1 ref frames.\n",
    "                    ref_begin = int((ref_frames[ref_idx-1]+ref_frames[ref_idx])/2)\n",
    "                    ref_end = full_array.shape[0]\n",
    "                else:\n",
    "                    #These are ref frames in the middle. There are >1 ref frames.\n",
    "                    ref_begin = int((ref_frames[ref_idx-1]+ref_frames[ref_idx])/2)\n",
    "                    ref_end = int((ref_frames[ref_idx]+ref_frames[ref_idx+1])/2)\n",
    "            #######################\n",
    "\n",
    "            #forward tracking\n",
    "            ##############################################################\n",
    "            if ref_frame < ref_end-1:  #can forward track only if there are frames after the ref_frame\n",
    "                previous_bbox = ref_bbox\n",
    "                valid = True\n",
    "\n",
    "                for frame in range(ref_frame, ref_end, step):\n",
    "\n",
    "                    full_frame = full_array[frame]\n",
    "\n",
    "                    if valid:\n",
    "                        search_w = int(previous_bbox[2]+(2*search_margin))\n",
    "                        search_h = int(previous_bbox[3]+(2*search_margin))\n",
    "                        search_x0 = int(previous_bbox[0] - ((search_w - previous_bbox[2])/2))\n",
    "                        search_y0 = int(previous_bbox[1] - ((search_h - previous_bbox[3])/2))\n",
    "                        search_bbox = (search_x0, search_y0, search_w, search_h)\n",
    "                        search_region = full_frame[search_y0:search_y0+search_h,\n",
    "                                                  search_x0:search_x0+search_w]\n",
    "\n",
    "                        all_search_bboxes[frame] = search_bbox\n",
    "\n",
    "                    else:\n",
    "                        all_search_x0 = [b[0] for b in all_search_bboxes[ref_frame+1:ref_end] if not(b is None)]\n",
    "                        median_x0 = np.median(all_search_x0)\n",
    "                        IQR_x0 = np.quantile(all_search_x0, 0.75) - np.quantile(all_search_x0, 0.25)\n",
    "                        all_search_x0 = [x for x in all_search_x0 if (x>=median_x0-(1.5*IQR_x0)) and (x<=median_x0+(1.5*IQR_x0))]\n",
    "                        min_search_x0 = min(all_search_x0)\n",
    "                        max_search_x0 = max(all_search_x0)\n",
    "\n",
    "                        all_search_y0 = [b[1] for b in all_search_bboxes[ref_frame+1:ref_end] if not(b is None)]\n",
    "                        median_y0 = np.median(all_search_y0)\n",
    "                        IQR_y0 = np.quantile(all_search_y0, 0.75) - np.quantile(all_search_y0, 0.25)\n",
    "                        all_search_y0 = [y for y in all_search_y0 if (y>=median_y0-(1.5*IQR_y0)) and (y<=median_y0+(1.5*IQR_y0))]\n",
    "                        min_search_y0 = min(all_search_y0)\n",
    "                        max_search_y0 = max(all_search_y0)\n",
    "\n",
    "                        search_x0 = min_search_x0\n",
    "                        search_y0 = min_search_y0\n",
    "                        search_w = (max_search_x0-min_search_x0) + int(ref_bbox[2]+(2*search_margin))\n",
    "                        search_h = (max_search_y0-min_search_y0) + int(previous_bbox[3]+(2*search_margin))\n",
    "                        search_bbox = (search_x0, search_y0, search_w, search_h)\n",
    "                        search_region = full_frame[search_y0:search_y0+search_h,\n",
    "                                                      search_x0:search_x0+search_w]    \n",
    "\n",
    "                    mean_corr, max_loc = compute_similarity_map(search_region, ref_patches, ref_idx)\n",
    "                    corr_with_ref[frame] = mean_corr\n",
    "                    \n",
    "                    if mean_corr >= threshold:\n",
    "                        valid = True\n",
    "                        current_w = ref_bbox[2]\n",
    "                        current_h = ref_bbox[3]\n",
    "                        current_x0 = search_x0 + max_loc[0]\n",
    "                        current_y0 = search_y0 + max_loc[1]\n",
    "                        current_bbox = (current_x0, current_y0, current_w, current_h)\n",
    "\n",
    "                        img_bbox = cv2.rectangle(cv2.cvtColor(full_frame, cv2.COLOR_GRAY2BGR),\n",
    "                                                     (search_x0, search_y0),\n",
    "                                                     (search_x0+search_w, search_y0+search_h),\n",
    "                                                     (255, 255, 255), 2)\n",
    "                        img_bbox = cv2.rectangle(img_bbox,\n",
    "                                                     (current_bbox[0], current_bbox[1]),\n",
    "                                                     (current_bbox[0] + current_bbox[2], current_bbox[1] + current_bbox[3]),\n",
    "                                                     (0, 255, 0), 2)\n",
    "                        img_bbox = cv2.putText(img_bbox, 'frame: '+str(frame), (25,25), cv2.FONT_HERSHEY_SIMPLEX,  \n",
    "                                       1, (0,255,0), 2, cv2.LINE_AA) \n",
    "                        img_bbox = cv2.putText(img_bbox, 'corr: '+str(mean_corr), (25,50), cv2.FONT_HERSHEY_SIMPLEX,  \n",
    "                                       1, (0,255,0), 2, cv2.LINE_AA) \n",
    "\n",
    "                        out_array[frame] = img_bbox\n",
    "\n",
    "                        all_lesion_bboxes[frame] = current_bbox[:]\n",
    "                        previous_bbox = current_bbox[:]\n",
    "                        \n",
    "                    else:\n",
    "                        valid = False\n",
    "                        img_bbox = cv2.rectangle(cv2.cvtColor(full_frame, cv2.COLOR_GRAY2BGR),\n",
    "                                                     (search_x0, search_y0),\n",
    "                                                     (search_x0+search_w, search_y0+search_h),\n",
    "                                                     (0, 0, 255), 2)\n",
    "                        img_bbox = cv2.putText(img_bbox, 'frame: '+str(frame), (25,25), cv2.FONT_HERSHEY_SIMPLEX,  \n",
    "                                       1, (0,0,255), 2, cv2.LINE_AA) \n",
    "                        img_bbox = cv2.putText(img_bbox, 'corr: '+str(mean_corr), (25,50), cv2.FONT_HERSHEY_SIMPLEX,  \n",
    "                                       1, (0,0,255), 2, cv2.LINE_AA) \n",
    "\n",
    "                        out_array[frame] = img_bbox\n",
    "            ##############################################################\n",
    "            \n",
    "            #backward tracking\n",
    "            ##############################################################\n",
    "            if ref_frame > ref_begin:  \n",
    "                previous_bbox = ref_bbox\n",
    "                valid = True\n",
    "\n",
    "                for frame in range(ref_frame-1, ref_begin-1, -step):\n",
    "\n",
    "                    full_frame = full_array[frame]\n",
    "\n",
    "                    if valid:\n",
    "                        search_w = int(previous_bbox[2]+(2*search_margin))\n",
    "                        search_h = int(previous_bbox[3]+(2*search_margin))\n",
    "                        search_x0 = int(previous_bbox[0] - ((search_w - previous_bbox[2])/2))\n",
    "                        search_y0 = int(previous_bbox[1] - ((search_h - previous_bbox[3])/2))\n",
    "                        search_bbox = (search_x0, search_y0, search_w, search_h)\n",
    "                        search_region = full_frame[search_y0:search_y0+search_h,\n",
    "                                                  search_x0:search_x0+search_w]\n",
    "\n",
    "                        all_search_bboxes[frame] = search_bbox\n",
    "\n",
    "                    else:\n",
    "                        all_search_x0 = [b[0] for b in all_search_bboxes[ref_begin:ref_frame] if not(b is None)]\n",
    "                        median_x0 = np.median(all_search_x0)\n",
    "                        IQR_x0 = np.quantile(all_search_x0, 0.75) - np.quantile(all_search_x0, 0.25)\n",
    "                        all_search_x0 = [x for x in all_search_x0 if (x>=median_x0-(1.5*IQR_x0)) and (x<=median_x0+(1.5*IQR_x0))]\n",
    "                        min_search_x0 = min(all_search_x0)\n",
    "                        max_search_x0 = max(all_search_x0)\n",
    "\n",
    "                        all_search_y0 = [b[1] for b in all_search_bboxes[ref_begin:ref_frame] if not(b is None)]\n",
    "                        median_y0 = np.median(all_search_y0)\n",
    "                        IQR_y0 = np.quantile(all_search_y0, 0.75) - np.quantile(all_search_y0, 0.25)\n",
    "                        all_search_y0 = [y for y in all_search_y0 if (y>=median_y0-(1.5*IQR_y0)) and (y<=median_y0+(1.5*IQR_y0))]\n",
    "                        min_search_y0 = min(all_search_y0)\n",
    "                        max_search_y0 = max(all_search_y0)\n",
    "\n",
    "                        search_x0 = min_search_x0\n",
    "                        search_y0 = min_search_y0\n",
    "                        search_w = (max_search_x0-min_search_x0) + int(ref_bbox[2]+(2*search_margin))\n",
    "                        search_h = (max_search_y0-min_search_y0) + int(previous_bbox[3]+(2*search_margin))\n",
    "                        search_bbox = (search_x0, search_y0, search_w, search_h)\n",
    "                        search_region = full_frame[search_y0:search_y0+search_h,\n",
    "                                                      search_x0:search_x0+search_w]    \n",
    "\n",
    "                    mean_corr, max_loc = compute_similarity_map(search_region, ref_patches, ref_idx)\n",
    "                    corr_with_ref[frame] = mean_corr\n",
    "                    \n",
    "                    if mean_corr >= threshold:\n",
    "                        valid = True\n",
    "                        current_w = ref_bbox[2]\n",
    "                        current_h = ref_bbox[3]\n",
    "                        current_x0 = search_x0 + max_loc[0]\n",
    "                        current_y0 = search_y0 + max_loc[1]\n",
    "                        current_bbox = (current_x0, current_y0, current_w, current_h)\n",
    "\n",
    "                        img_bbox = cv2.rectangle(cv2.cvtColor(full_frame, cv2.COLOR_GRAY2BGR),\n",
    "                                                     (search_x0, search_y0),\n",
    "                                                     (search_x0+search_w, search_y0+search_h),\n",
    "                                                     (255, 255, 255), 2)\n",
    "                        img_bbox = cv2.rectangle(img_bbox,\n",
    "                                                     (current_bbox[0], current_bbox[1]),\n",
    "                                                     (current_bbox[0] + current_bbox[2], current_bbox[1] + current_bbox[3]),\n",
    "                                                     (0, 255, 0), 2)\n",
    "                        img_bbox = cv2.putText(img_bbox, 'frame: '+str(frame), (25,25), cv2.FONT_HERSHEY_SIMPLEX,  \n",
    "                                       1, (0,255,0), 2, cv2.LINE_AA) \n",
    "                        img_bbox = cv2.putText(img_bbox, 'corr: '+str(mean_corr), (25,50), cv2.FONT_HERSHEY_SIMPLEX,  \n",
    "                                       1, (0,255,0), 2, cv2.LINE_AA) \n",
    "\n",
    "                        out_array[frame] = img_bbox\n",
    "\n",
    "                        all_lesion_bboxes[frame] = current_bbox[:]\n",
    "                        previous_bbox = current_bbox[:]\n",
    "                        \n",
    "                    else:\n",
    "                        valid = False\n",
    "                        img_bbox = cv2.rectangle(cv2.cvtColor(full_frame, cv2.COLOR_GRAY2BGR),\n",
    "                                                     (search_x0, search_y0),\n",
    "                                                     (search_x0+search_w, search_y0+search_h),\n",
    "                                                     (0, 0, 255), 2)\n",
    "                        img_bbox = cv2.putText(img_bbox, 'frame: '+str(frame), (25,25), cv2.FONT_HERSHEY_SIMPLEX,  \n",
    "                                       1, (0,0,255), 2, cv2.LINE_AA) \n",
    "                        img_bbox = cv2.putText(img_bbox, 'corr: '+str(mean_corr), (25,50), cv2.FONT_HERSHEY_SIMPLEX,  \n",
    "                                       1, (0,0,255), 2, cv2.LINE_AA) \n",
    "\n",
    "                        out_array[frame] = img_bbox\n",
    "            ##############################################################\n",
    "            \n",
    "\n",
    "        #check if lesion bbox in any frame move in this iteration\n",
    "        #####################\n",
    "        bbox_move = check_bbox_move(previous_all_lesion_bboxes, all_lesion_bboxes)\n",
    "        if bbox_move or (threshold < min([e for e in corr_with_ref if not(e is None)])):\n",
    "            break\n",
    "        #####################\n",
    "\n",
    "        previous_threshold = threshold\n",
    "        previous_all_lesion_bboxes = all_lesion_bboxes[:]\n",
    "        previous_out_array = out_array.copy()\n",
    "        previous_corr_with_ref = corr_with_ref.copy()\n",
    "        threshold -= threshold_decrease_per_step\n",
    "        iteration += 1\n",
    "     \n",
    "    print('iteration:', iteration-1)\n",
    "    print('threshold:', previous_threshold)\n",
    "\n",
    "    out_array = previous_out_array.copy()\n",
    "   \n",
    "    export_video(out_array, mp4_path, CineRate=10)\n",
    "    \n",
    "    return full_array, previous_all_lesion_bboxes, ref_frames, bboxes, masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 12)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P_001\n",
      "../sample-data/P_001/pickle_bmode_CE_gray/ceus_inj1_wi_000000.000000.pkl\n",
      "(753, 802, 1442)\n",
      "(753, 802, 1442)\n",
      "initial threshold: 0.9999998807907104\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 2\n",
      "threshold: 0.9799998807907104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x44495658/'XVID' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usable bboxes: 625\n",
      "outlier bboxes: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:33<00:00, 33.18s/it]\n"
     ]
    }
   ],
   "source": [
    "for ROI_margin_suffix in ROI_margin_suffix_list:\n",
    "    for frame_rate_suffix in frame_rate_suffix_list:\n",
    "        \n",
    "        export_dir = export_dir_prefix + ROI_margin_suffix + '_' + frame_rate_suffix\n",
    "        \n",
    "        df = pd.read_excel(dataset_path, dtype=str)\n",
    "        print(df.shape)\n",
    "        \n",
    "        for col in df.columns:\n",
    "            if col.endswith('_path'):\n",
    "                df.loc[:,col] = df[col].apply(add_data_dir, args=(data_dir,))\n",
    "                \n",
    "        for row_idx in tqdm(df.index):\n",
    "            patient_code_inj = df.loc[row_idx, 'patient_code_inj']\n",
    "            print(patient_code_inj)\n",
    "            pickle_full_path = df.loc[row_idx, 'pickle_bmode_CE_gray_path']\n",
    "            print(pickle_full_path)\n",
    "            mp4_path = join(export_mp4_dir, patient_code_inj+'.mp4')\n",
    "            nifti_segmentation_path = df.loc[row_idx, 'nifti_segmentation_path']\n",
    "\n",
    "            full_array, bmode_MC_bboxes, ref_frames, ref_bboxes, ref_masks = perform_MC(pickle_full_path, \n",
    "                                                                                        nifti_segmentation_path, \n",
    "                                                                                        mp4_path,\n",
    "                                                                                        ROI_margin_suffix, \n",
    "                                                                                        frame_rate_suffix)\n",
    "\n",
    "            #resize all MC bboxes to the same size\n",
    "            bmode_MC_bboxes = resize_MC_bboxes(bmode_MC_bboxes)\n",
    "\n",
    "            #remove outlier bboxes\n",
    "            bmode_MC_bboxes = remove_outlier_bboxes(bmode_MC_bboxes, full_array)\n",
    "\n",
    "            n_frames = full_array.shape[0]\n",
    "\n",
    "            x0_bmode = int(df.loc[row_idx, 'x0_bmode'])\n",
    "            y0_bmode = int(df.loc[row_idx, 'y0_bmode'])\n",
    "            w_bmode = int(df.loc[row_idx, 'w_bmode'])\n",
    "            h_bmode = int(df.loc[row_idx, 'h_bmode'])\n",
    "            x0_CE = int(df.loc[row_idx, 'x0_CE'])\n",
    "            y0_CE = int(df.loc[row_idx, 'y0_CE'])\n",
    "            w_CE = int(df.loc[row_idx, 'w_CE'])\n",
    "            h_CE = int(df.loc[row_idx, 'h_CE'])\n",
    "            CE_side = df.loc[row_idx, 'CE_window_left(l)_or_right(r)']\n",
    "\n",
    "            CE_MC_bboxes = create_CE_MC_bboxes(bmode_MC_bboxes, x0_bmode, x0_CE, CE_side)\n",
    "            bmode_ori_bboxes = create_ori_bboxes(ref_frames, ref_bboxes, n_frames).astype('int')\n",
    "            CE_ori_bboxes = create_CE_ori_bboxes(bmode_ori_bboxes, x0_bmode, x0_CE, CE_side).astype('int')\n",
    "\n",
    "            #cut ROI\n",
    "            if not fixed_size_ROI:\n",
    "                #use \"cut_ROI\" function to get ROI exactly fit to the lesion\n",
    "                bmode_MC_ROI = cut_ROI(full_array, bmode_MC_bboxes)\n",
    "                CE_MC_ROI = cut_ROI(full_array, CE_MC_bboxes)\n",
    "            else:\n",
    "                #use \"cut_ROI200\" function to get a fixed size ROI\n",
    "                bmode_MC_ROI = cut_ROI200(full_array, bmode_MC_bboxes, (x0_bmode,y0_bmode,w_bmode,h_bmode))\n",
    "                CE_MC_ROI = cut_ROI200(full_array, CE_MC_bboxes, (x0_CE,y0_CE,w_CE,h_CE))\n",
    "\n",
    "            export_pickle(bmode_MC_ROI, join(export_dir, patient_code_inj, 'bmode_MC_ROI.pkl'))\n",
    "            export_pickle(CE_MC_ROI, join(export_dir, patient_code_inj, 'CE_MC_ROI.pkl'))\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-11.m91",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-11:m91"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from os.path import join, isfile, exists, isdir, dirname\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '../sample-data/dataset_synthesize.xlsx'\n",
    "data_dir = '../sample-data'\n",
    "\n",
    "export_dir_prefix = '../outputs/'\n",
    "export_excel_path = '../outputs/motion-compensation.xlsx'\n",
    "export_mp4_dir = '../outputs/mp4-outputs'\n",
    "\n",
    "ROI_margin_suffix_list = ['withoutROImargin']  #['withROImargin', 'withoutROImargin']\n",
    "frame_rate_suffix_list = ['fullFrameRate']  #['halfFrameRate', 'fullFrameRate']\n",
    "\n",
    "fixed_size_ROI = False  #if True, the output ROIs will have a fixed size, rather than fitted to the lesion\n",
    "\n",
    "set_quantile = 0.50  #initial quantile\n",
    "threshold_decrease_per_step = 0.02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_data_dir(x, data_dir):\n",
    "    if pd.isna(x):\n",
    "        return None\n",
    "    else:\n",
    "        return join(data_dir, x)\n",
    "\n",
    "\n",
    "\n",
    "def load_pickle(pickle_path):\n",
    "    with open(pickle_path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    print(data.shape)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "def find_ref_frames_from_nifti(nifti_path, ROI_margin_suffix, search_margin):\n",
    "    \n",
    "    nifti_array = np.transpose(nib.load(nifti_path).get_fdata()).astype(int)\n",
    "    print(nifti_array.shape)  # expected (frames, height, width)\n",
    "\n",
    "    spatial_sum = np.sum(nifti_array, axis=(1, 2))  # shape (frames,)\n",
    "    ref_frames = np.argwhere(spatial_sum > 0)\n",
    "    ref_frames = np.reshape(ref_frames, ref_frames.shape[0])\n",
    "\n",
    "    if ROI_margin_suffix == 'withROImargin':\n",
    "        ROI_margin = int(search_margin/2)\n",
    "    elif ROI_margin_suffix == 'withoutROImargin':\n",
    "        ROI_margin = 0\n",
    "    \n",
    "    bboxes = []\n",
    "    masks = []\n",
    "    for i,ref_frame in enumerate(ref_frames):\n",
    "        mask = nifti_array[ref_frame]\n",
    "        pos_coor = np.argwhere(mask > 0)\n",
    "        x_values = pos_coor[:, 1]\n",
    "        y_values = pos_coor[:, 0]\n",
    "        x0 = x_values.min()\n",
    "        x1 = x_values.max()\n",
    "        w = x1 - x0 + 1\n",
    "        y0 = y_values.min()\n",
    "        y1 = y_values.max()\n",
    "        h = y1 - y0 + 1\n",
    "        \n",
    "        bboxes.append((x0-ROI_margin,\n",
    "                       y0-ROI_margin,\n",
    "                       w+(2*ROI_margin),\n",
    "                       h+(2*ROI_margin)))\n",
    "        masks.append(mask[y0-ROI_margin:y0-ROI_margin+h+(2*ROI_margin), \n",
    "                          x0-ROI_margin:x0-ROI_margin+w+(2*ROI_margin)])\n",
    "\n",
    "    return ref_frames, bboxes, masks\n",
    "\n",
    "\n",
    "\n",
    "def export_video(cine_array, mp4_path, CineRate):\n",
    "\n",
    "    mp4_dir = dirname(mp4_path)\n",
    "    if not exists(mp4_dir):\n",
    "        os.makedirs(mp4_dir)\n",
    "\n",
    "    width = cine_array.shape[2]\n",
    "    height = cine_array.shape[1]\n",
    "    if pd.notna(CineRate):\n",
    "        frame_rate = int(CineRate)\n",
    "    else:\n",
    "        print('no CineRate in excel file; using default frame rate = 9')\n",
    "        frame_rate = 9\n",
    "\n",
    "    writer = cv2.VideoWriter(mp4_path, cv2.VideoWriter_fourcc(*'XVID'), frame_rate, (width, height))\n",
    "\n",
    "    if len(cine_array.shape) == 3:  # grayscale\n",
    "        for frame in range(cine_array.shape[0]):\n",
    "            writer.write(cv2.cvtColor(cine_array[frame], cv2.COLOR_GRAY2BGR))\n",
    "    elif len(cine_array.shape) == 4:  # RGB\n",
    "        for frame in range(cine_array.shape[0]):\n",
    "            writer.write(cine_array[frame])\n",
    "    else:\n",
    "        print('color channel not compatible for video exporting; please check dimension of array.')\n",
    "\n",
    "    writer.release()\n",
    "    \n",
    "    \n",
    "    \n",
    "def apply_blur(cine_array):\n",
    "    out = np.zeros(cine_array.shape)\n",
    "    for frame in range(cine_array.shape[0]):\n",
    "        img = cine_array[frame]\n",
    "        img = cv2.GaussianBlur(img, (21, 21), 0)\n",
    "        out[frame] = img\n",
    "    out = out.astype(np.uint8)\n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "def plot_correlation(corr_with_ref, threshold):\n",
    "    plt.figure(figsize=(24,6))\n",
    "    plt.axhline(threshold, color='b')\n",
    "    plt.plot(range(len(corr_with_ref)), corr_with_ref, marker='o', color='g', label='corr_with_ref')\n",
    "    plt.ylim(0,1.0)\n",
    "    plt.ylabel('corr_coef')\n",
    "    plt.xlabel('frame')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "def find_correlation(bmode, ref_bmodes, set_quantile):\n",
    "    \n",
    "    n_refs = len(ref_bmodes)\n",
    "    n_frames = bmode.shape[0]\n",
    "    correlations = np.zeros((n_refs, n_frames))\n",
    "    \n",
    "    for ref_idx in range(n_refs):\n",
    "        ref = ref_bmodes[ref_idx]\n",
    "        for frame in range(n_frames):\n",
    "            similarity_map = cv2.matchTemplate(bmode[frame], ref, cv2.TM_CCOEFF_NORMED)\n",
    "            min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(similarity_map)\n",
    "            correlations[ref_idx, frame] = max_val\n",
    "            \n",
    "    correlations = np.mean(correlations, axis=0)\n",
    "    threshold = np.quantile(correlations, set_quantile)\n",
    "    \n",
    "    return correlations, threshold\n",
    "\n",
    "\n",
    "\n",
    "def check_bbox_move(previous_all_lesion_bboxes, all_lesion_bboxes):\n",
    "    \n",
    "    bbox_move = False\n",
    "    \n",
    "    for frame in range(len(previous_all_lesion_bboxes)):\n",
    "        previous_bbox = previous_all_lesion_bboxes[frame]\n",
    "        current_bbox = all_lesion_bboxes[frame]\n",
    "        if not(previous_bbox is None):\n",
    "            if not(previous_bbox == current_bbox):\n",
    "                bbox_move = True\n",
    "                break\n",
    "    \n",
    "    return bbox_move\n",
    "\n",
    "\n",
    "\n",
    "def compute_similarity_map(search_region, ref_patches, current_ref_idx):\n",
    "    \n",
    "    n_refs = len(ref_patches)\n",
    "    corrs = np.zeros((n_refs,))\n",
    "    \n",
    "    for ref_idx in range(n_refs):\n",
    "        ref = ref_patches[ref_idx]\n",
    "        similarity_map = cv2.matchTemplate(search_region, ref, cv2.TM_CCOEFF_NORMED)\n",
    "        min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(similarity_map)\n",
    "        corrs[ref_idx] = max_val\n",
    "        if current_ref_idx == ref_idx:\n",
    "            current_max_loc = max_loc\n",
    "            \n",
    "    mean_corr = np.mean(corrs)\n",
    "            \n",
    "    return mean_corr, current_max_loc\n",
    "\n",
    "\n",
    "\n",
    "def resize_MC_bboxes(bboxes):\n",
    "    #resize bboxes to minimum width and height\n",
    "    \n",
    "    min_w = min([b[2] for b in bboxes if not(b is None)])\n",
    "    min_h = min([b[3] for b in bboxes if not(b is None)])\n",
    "    \n",
    "    for i in range(len(bboxes)):\n",
    "        if bboxes[i] is None:\n",
    "            continue\n",
    "        x0, y0, w, h = bboxes[i]\n",
    "        new_w = min_w\n",
    "        new_h = min_h\n",
    "        new_x0 = x0 + int((w-new_w)/2)\n",
    "        new_y0 = y0 + int((h-new_h)/2)\n",
    "        bboxes[i] = (new_x0, new_y0, new_w, new_h)\n",
    "        \n",
    "    return bboxes\n",
    "\n",
    "\n",
    "\n",
    "def create_CE_MC_bboxes(bmode_bboxes, x0_bmode, x0_CE, CE_side):\n",
    "    \n",
    "    CE_bboxes = [None] * len(bmode_bboxes)\n",
    "    \n",
    "    for i in range(len(bmode_bboxes)):\n",
    "        if bmode_bboxes[i] is None:\n",
    "            continue\n",
    "        x0, y0, w, h = bmode_bboxes[i]\n",
    "        \n",
    "        if CE_side == 'r':\n",
    "            new_x0 = x0 + (x0_CE-x0_bmode)\n",
    "        elif CE_side == 'l':\n",
    "            new_x0 = x0 - (x0_bmode-x0_CE)\n",
    "        else:\n",
    "            raise Exception('Error in create_CE_MC_bboxes')\n",
    "            \n",
    "        CE_bboxes[i] = (new_x0, y0, w, h)\n",
    "    \n",
    "    return CE_bboxes\n",
    "\n",
    "\n",
    "\n",
    "def create_segmentation_masks(ref_frames, ref_masks, n_frames):\n",
    "    \n",
    "    min_h = min([m.shape[0] for m in ref_masks])\n",
    "    min_w = min([m.shape[1] for m in ref_masks])\n",
    "    \n",
    "    seg_masks = np.zeros((n_frames, min_h, min_w))\n",
    "    \n",
    "    for ref_idx in range(ref_frames.shape[0]):\n",
    "        ref_frame = ref_frames[ref_idx]\n",
    "        \n",
    "        #compute the temporal segment the ref_frame is responsible for\n",
    "        if ref_idx == 0:\n",
    "            if ref_idx == ref_frames.shape[0] - 1:\n",
    "                #There is only 1 ref_frame\n",
    "                ref_begin = 0\n",
    "                ref_end = n_frames\n",
    "            else:\n",
    "                #This is the first ref_frame. There are >1 ref frames.\n",
    "                ref_begin = 0\n",
    "                ref_end = int((ref_frames[ref_idx]+ref_frames[ref_idx+1])/2)\n",
    "        else:\n",
    "            if ref_idx == ref_frames.shape[0] - 1:\n",
    "                #This is the last ref frame. There are >1 ref frames.\n",
    "                ref_begin = int((ref_frames[ref_idx-1]+ref_frames[ref_idx])/2)\n",
    "                ref_end = n_frames\n",
    "            else:\n",
    "                #These are ref frames in the middle. There are >1 ref frames.\n",
    "                ref_begin = int((ref_frames[ref_idx-1]+ref_frames[ref_idx])/2)\n",
    "                ref_end = int((ref_frames[ref_idx]+ref_frames[ref_idx+1])/2)\n",
    "        \n",
    "        ref_mask = ref_masks[ref_idx]\n",
    "        h = ref_mask.shape[0]\n",
    "        w = ref_mask.shape[1]\n",
    "        x0 = int((w-min_w)/2)\n",
    "        y0 = int((h-min_h)/2)\n",
    "        \n",
    "        seg_masks[ref_begin:ref_end] = ref_mask[y0:y0+min_h, x0:x0+min_w]   #broadcast\n",
    "        \n",
    "    return seg_masks\n",
    "\n",
    "\n",
    "\n",
    "def create_segmentation_masks200(ref_frames, ref_masks, n_frames, ROI_w, ROI_h):\n",
    "    \n",
    "    min_h = min([m.shape[0] for m in ref_masks])\n",
    "    min_w = min([m.shape[1] for m in ref_masks])\n",
    "    \n",
    "    seg_masks = np.zeros((n_frames, ROI_h, ROI_w))\n",
    "    \n",
    "    for ref_idx in range(ref_frames.shape[0]):\n",
    "        ref_frame = ref_frames[ref_idx]\n",
    "        \n",
    "        #compute the temporal segment the ref_frame is responsible for\n",
    "        if ref_idx == 0:\n",
    "            if ref_idx == ref_frames.shape[0] - 1:\n",
    "                #There is only 1 ref_frame\n",
    "                ref_begin = 0\n",
    "                ref_end = n_frames\n",
    "            else:\n",
    "                #This is the first ref_frame. There are >1 ref frames.\n",
    "                ref_begin = 0\n",
    "                ref_end = int((ref_frames[ref_idx]+ref_frames[ref_idx+1])/2)\n",
    "        else:\n",
    "            if ref_idx == ref_frames.shape[0] - 1:\n",
    "                #This is the last ref frame. There are >1 ref frames.\n",
    "                ref_begin = int((ref_frames[ref_idx-1]+ref_frames[ref_idx])/2)\n",
    "                ref_end = n_frames\n",
    "            else:\n",
    "                #These are ref frames in the middle. There are >1 ref frames.\n",
    "                ref_begin = int((ref_frames[ref_idx-1]+ref_frames[ref_idx])/2)\n",
    "                ref_end = int((ref_frames[ref_idx]+ref_frames[ref_idx+1])/2)\n",
    "        \n",
    "        ref_mask = ref_masks[ref_idx]\n",
    "        h = ref_mask.shape[0]\n",
    "        w = ref_mask.shape[1]\n",
    "        x0 = int((w-min_w)/2)\n",
    "        y0 = int((h-min_h)/2)\n",
    "        \n",
    "        top_offset = int((ROI_h-min_h)/2)\n",
    "        left_offset = int((ROI_w-min_w)/2)\n",
    "        seg_masks[ref_begin:ref_end, top_offset:top_offset+min_h, left_offset:left_offset+min_w] = ref_mask[y0:y0+min_h, x0:x0+min_w]   #broadcast\n",
    "        \n",
    "    return seg_masks\n",
    "\n",
    "\n",
    "\n",
    "def create_ori_bboxes(ref_frames, ref_bboxes, n_frames):\n",
    "    min_h = min([b[3] for b in ref_bboxes])\n",
    "    min_w = min([b[2] for b in ref_bboxes])\n",
    "    \n",
    "    ori_bboxes = np.zeros((n_frames, 4))\n",
    "    \n",
    "    for ref_idx in range(ref_frames.shape[0]):\n",
    "        ref_frame = ref_frames[ref_idx]\n",
    "        \n",
    "        #compute the temporal segment the ref_frame is responsible for\n",
    "        if ref_idx == 0:\n",
    "            if ref_idx == ref_frames.shape[0] - 1:\n",
    "                #There is only 1 ref_frame\n",
    "                ref_begin = 0\n",
    "                ref_end = n_frames\n",
    "            else:\n",
    "                #This is the first ref_frame. There are >1 ref frames.\n",
    "                ref_begin = 0\n",
    "                ref_end = int((ref_frames[ref_idx]+ref_frames[ref_idx+1])/2)\n",
    "        else:\n",
    "            if ref_idx == ref_frames.shape[0] - 1:\n",
    "                #This is the last ref frame. There are >1 ref frames.\n",
    "                ref_begin = int((ref_frames[ref_idx-1]+ref_frames[ref_idx])/2)\n",
    "                ref_end = n_frames\n",
    "            else:\n",
    "                #These are ref frames in the middle. There are >1 ref frames.\n",
    "                ref_begin = int((ref_frames[ref_idx-1]+ref_frames[ref_idx])/2)\n",
    "                ref_end = int((ref_frames[ref_idx]+ref_frames[ref_idx+1])/2)\n",
    "        \n",
    "        x0,y0,w,h = ref_bboxes[ref_idx]\n",
    "        new_w = min_w\n",
    "        new_h = min_h\n",
    "        new_x0 = x0 + int((w-new_w)/2)\n",
    "        new_y0 = y0 + int((h-new_h)/2)\n",
    "        \n",
    "        new_bbox = np.array([new_x0, new_y0, new_w, new_h])\n",
    "        \n",
    "        ori_bboxes[ref_begin:ref_end] = new_bbox   #broadcast\n",
    "        \n",
    "    return ori_bboxes\n",
    "\n",
    "\n",
    "\n",
    "def create_CE_ori_bboxes(bmode_bboxes, x0_bmode, x0_CE, CE_side):\n",
    "    CE_bboxes = bmode_bboxes.copy()\n",
    "        \n",
    "    if CE_side == 'r':\n",
    "        CE_bboxes[:,0] = CE_bboxes[:,0] + (x0_CE-x0_bmode)\n",
    "    elif CE_side == 'l':\n",
    "        CE_bboxes[:,0] = CE_bboxes[:,0] - (x0_bmode-x0_CE)\n",
    "    else:\n",
    "        raise Exception('Error in create_CE_ori_bboxes')\n",
    "            \n",
    "    return CE_bboxes\n",
    "\n",
    "\n",
    "\n",
    "def cut_ROI(full_array, bboxes):\n",
    "    \n",
    "    min_w = min([b[2] for b in bboxes if not(b is None)])\n",
    "    min_h = min([b[3] for b in bboxes if not(b is None)])\n",
    "    \n",
    "    ROI = np.zeros((full_array.shape[0], min_h, min_w))\n",
    "    \n",
    "    for frame in range(full_array.shape[0]):\n",
    "        bbox = bboxes[frame]\n",
    "        if bbox is None:  #skip MC frames without bbox (due to out-of-frame motion)\n",
    "            continue\n",
    "        x0,y0,w,h = bbox\n",
    "        ROI[frame] = full_array[frame, y0:y0+h, x0:x0+w]\n",
    "    \n",
    "    return ROI\n",
    "\n",
    "\n",
    "\n",
    "def cut_ROI200(full_array, bboxes, window_loc):\n",
    "    \n",
    "    min_w = min([b[2] for b in bboxes if not(b is None)])\n",
    "    min_h = min([b[3] for b in bboxes if not(b is None)])\n",
    "    \n",
    "    window_x0, window_y0, window_w, window_h = window_loc\n",
    "    \n",
    "    cut_h = int(max(0.4*window_h, min_h, min_w))\n",
    "    cut_w = cut_h\n",
    "    \n",
    "    ROI = np.zeros((full_array.shape[0], cut_h, cut_w))\n",
    "    \n",
    "    for frame in range(full_array.shape[0]):\n",
    "        bbox = bboxes[frame]\n",
    "        if bbox is None:  #skip MC frames without bbox (due to out-of-frame motion)\n",
    "            continue\n",
    "        x0,y0,w,h = bbox\n",
    "        x_center = x0 + int(w/2)\n",
    "        y_center = y0 + int(h/2)\n",
    "        valid_w = min(int(x_center+cut_w/2),window_x0+window_w) - max(int(x_center-cut_w/2),window_x0)\n",
    "        valid_h = min(int(y_center+cut_h/2),window_y0+window_h) - max(int(y_center-cut_h/2),window_y0)\n",
    "        center_ROI = int(cut_h/2)\n",
    "        ROI[frame, int(center_ROI-valid_h/2):int(center_ROI+valid_h/2), int(center_ROI-valid_w/2):int(center_ROI+valid_w/2)] = full_array[frame, \n",
    "                                max(int(y_center-cut_h/2),window_y0):min(int(y_center+cut_h/2),window_y0+window_h), \n",
    "                                max(int(x_center-cut_w/2),window_x0):min(int(x_center+cut_w/2),window_x0+window_w)]\n",
    "    \n",
    "    return ROI\n",
    "\n",
    "\n",
    "\n",
    "def visualize_ROI(bmode_ori_ROI, CE_ori_ROI, bmode_MC_ROI, CE_MC_ROI, seg_masks):\n",
    "    n_frames = bmode_ori_ROI.shape[0]\n",
    "    \n",
    "    for frame in range(min(n_frames,100)):\n",
    "        print('frame:', frame)\n",
    "        plt.figure()\n",
    "        plt.subplot(1,5,1)\n",
    "        plt.imshow(bmode_ori_ROI[frame], cmap='gray')\n",
    "        plt.subplot(1,5,2)\n",
    "        plt.imshow(CE_ori_ROI[frame], cmap='gray')\n",
    "        plt.subplot(1,5,3)\n",
    "        plt.imshow(bmode_MC_ROI[frame], cmap='gray')\n",
    "        plt.subplot(1,5,4)\n",
    "        plt.imshow(CE_MC_ROI[frame], cmap='gray')\n",
    "        plt.subplot(1,5,5)\n",
    "        plt.imshow(seg_masks[frame], cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "        \n",
    "def export_pickle(cine_array, pickle_path):\n",
    "    \n",
    "    pickle_dir = dirname(pickle_path)\n",
    "    if not exists(pickle_dir):\n",
    "        os.makedirs(pickle_dir)\n",
    "\n",
    "    with open(pickle_path, 'wb') as wr:\n",
    "        pickle.dump(cine_array, wr, protocol=4)\n",
    "        \n",
    "        \n",
    "        \n",
    "def remove_outlier_bboxes(bboxes, full_array):\n",
    "    \n",
    "    all_x0 = [b[0] for b in bboxes if not(b is None)]\n",
    "    median_x0 = np.median(all_x0)\n",
    "    q1_x0 = np.quantile(all_x0, 0.25)\n",
    "    q3_x0 = np.quantile(all_x0, 0.75)\n",
    "    IQR_x0 = q3_x0 - q1_x0\n",
    "    \n",
    "    all_y0 = [b[1] for b in bboxes if not(b is None)]\n",
    "    median_y0 = np.median(all_y0)\n",
    "    q1_y0 = np.quantile(all_y0, 0.25)\n",
    "    q3_y0 = np.quantile(all_y0, 0.75)\n",
    "    IQR_y0 = q3_y0 - q1_y0\n",
    "    \n",
    "    out_bboxes = [None]*len(bboxes)\n",
    "    outliers = [None]*len(bboxes)\n",
    "    for i,b in enumerate(bboxes):\n",
    "        if not(b is None):\n",
    "            if (b[0]>=q1_x0-(1.5*IQR_x0)) and (b[0]<=q3_x0+(1.5*IQR_x0)) and \\\n",
    "            (b[1]>=q1_y0-(1.5*IQR_y0)) and (b[1]<=q3_y0+(1.5*IQR_y0)):\n",
    "                out_bboxes[i] = b[:]\n",
    "            else:\n",
    "                outliers[i] = b[:]\n",
    "                \n",
    "    print('usable bboxes:', len([b for b in out_bboxes if not(b is None)]))\n",
    "    print('outlier bboxes:', len([b for b in outliers if not(b is None)]))\n",
    "    \n",
    "    return out_bboxes\n",
    "\n",
    "\n",
    "\n",
    "def perform_MC(pickle_full_path, nifti_segmentation_path, mp4_path,\n",
    "              ROI_margin_suffix, frame_rate_suffix):\n",
    "    \n",
    "    if frame_rate_suffix == 'fullFrameRate':\n",
    "        step = 1\n",
    "    elif frame_rate_suffix == 'halfFrameRate':\n",
    "        step = 2\n",
    "    \n",
    "    full_array = load_pickle(pickle_full_path).astype(np.uint8)\n",
    "    \n",
    "    full_h = full_array.shape[1]\n",
    "    search_margin = int((0.5/15)*full_h)\n",
    "\n",
    "    ref_frames, bboxes, masks = find_ref_frames_from_nifti(nifti_segmentation_path, ROI_margin_suffix, search_margin)\n",
    "\n",
    "    #############################################################\n",
    "    #find initial correlation in the first run\n",
    "    min_x0 = min([e[0] for e in bboxes]) - search_margin\n",
    "    max_x1 = max([e[0]+e[2] for e in bboxes]) + search_margin\n",
    "    min_y0 = min([e[1] for e in bboxes]) - search_margin\n",
    "    max_y1 = max([e[1]+e[3] for e in bboxes]) + search_margin\n",
    "    bmode = full_array[:,\n",
    "                  min_y0:max_y1,\n",
    "                  min_x0:max_x1]\n",
    "    ref_bmodes = []\n",
    "    for ri in range(ref_frames.shape[0]):\n",
    "        ref_f = ref_frames[ri]\n",
    "        ref_b = bboxes[ri]\n",
    "        ref_bmodes.append(full_array[ref_f,\n",
    "                                    ref_b[1]:ref_b[1]+ref_b[3],\n",
    "                                    ref_b[0]:ref_b[0]+ref_b[2]])\n",
    "    corr_initial_run, threshold = find_correlation(bmode, ref_bmodes, set_quantile)\n",
    "    print('initial threshold:', threshold)\n",
    "    ############################################################\n",
    "    \n",
    "    ref_patches = ref_bmodes[:]\n",
    "    \n",
    "    previous_all_lesion_bboxes = [None]*full_array.shape[0]\n",
    "    iteration = 1\n",
    "        \n",
    "    while True:\n",
    "        \n",
    "        out_array = np.zeros(list(full_array.shape)+[3], dtype=np.uint8)\n",
    "        \n",
    "        all_search_bboxes = [None]*full_array.shape[0]\n",
    "        all_lesion_bboxes = [None]*full_array.shape[0]\n",
    "        corr_with_ref = [None]*full_array.shape[0]\n",
    "    \n",
    "        for ref_idx in range(ref_frames.shape[0]):\n",
    "            ref_frame = ref_frames[ref_idx]\n",
    "            ref_bbox = bboxes[ref_idx]\n",
    "\n",
    "            #show location of the ref_bbox\n",
    "            if iteration == 1 and ref_idx==0:\n",
    "                img_bbox = cv2.rectangle(cv2.cvtColor(full_array[ref_frame], cv2.COLOR_GRAY2BGR),\n",
    "                                             (ref_bbox[0], ref_bbox[1]),\n",
    "                                             (ref_bbox[0] + ref_bbox[2], ref_bbox[1] + ref_bbox[3]),\n",
    "                                             (0, 255, 0), 5)\n",
    "                plt.imshow(img_bbox)\n",
    "                plt.show()\n",
    "\n",
    "            #compute the temporal segment the ref_frame is responsible for\n",
    "            #######################\n",
    "            if ref_idx == 0:\n",
    "                if ref_idx == ref_frames.shape[0] - 1:\n",
    "                    #There is only 1 ref_frame\n",
    "                    ref_begin = 0\n",
    "                    ref_end = full_array.shape[0]\n",
    "                else:\n",
    "                    #This is the first ref_frame. There are >1 ref frames.\n",
    "                    ref_begin = 0\n",
    "                    ref_end = int((ref_frames[ref_idx]+ref_frames[ref_idx+1])/2)\n",
    "            else:\n",
    "                if ref_idx == ref_frames.shape[0] - 1:\n",
    "                    #This is the last ref frame. There are >1 ref frames.\n",
    "                    ref_begin = int((ref_frames[ref_idx-1]+ref_frames[ref_idx])/2)\n",
    "                    ref_end = full_array.shape[0]\n",
    "                else:\n",
    "                    #These are ref frames in the middle. There are >1 ref frames.\n",
    "                    ref_begin = int((ref_frames[ref_idx-1]+ref_frames[ref_idx])/2)\n",
    "                    ref_end = int((ref_frames[ref_idx]+ref_frames[ref_idx+1])/2)\n",
    "            #######################\n",
    "\n",
    "            #forward tracking\n",
    "            ##############################################################\n",
    "            if ref_frame < ref_end-1:  #can forward track only if there are frames after the ref_frame\n",
    "                previous_bbox = ref_bbox\n",
    "                valid = True\n",
    "\n",
    "                for frame in range(ref_frame, ref_end, step):\n",
    "\n",
    "                    full_frame = full_array[frame]\n",
    "\n",
    "                    if valid:\n",
    "                        search_w = int(previous_bbox[2]+(2*search_margin))\n",
    "                        search_h = int(previous_bbox[3]+(2*search_margin))\n",
    "                        search_x0 = int(previous_bbox[0] - ((search_w - previous_bbox[2])/2))\n",
    "                        search_y0 = int(previous_bbox[1] - ((search_h - previous_bbox[3])/2))\n",
    "                        search_bbox = (search_x0, search_y0, search_w, search_h)\n",
    "                        search_region = full_frame[search_y0:search_y0+search_h,\n",
    "                                                  search_x0:search_x0+search_w]\n",
    "\n",
    "                        all_search_bboxes[frame] = search_bbox\n",
    "\n",
    "                    else:\n",
    "                        all_search_x0 = [b[0] for b in all_search_bboxes[ref_frame+1:ref_end] if not(b is None)]\n",
    "                        median_x0 = np.median(all_search_x0)\n",
    "                        IQR_x0 = np.quantile(all_search_x0, 0.75) - np.quantile(all_search_x0, 0.25)\n",
    "                        all_search_x0 = [x for x in all_search_x0 if (x>=median_x0-(1.5*IQR_x0)) and (x<=median_x0+(1.5*IQR_x0))]\n",
    "                        min_search_x0 = min(all_search_x0)\n",
    "                        max_search_x0 = max(all_search_x0)\n",
    "\n",
    "                        all_search_y0 = [b[1] for b in all_search_bboxes[ref_frame+1:ref_end] if not(b is None)]\n",
    "                        median_y0 = np.median(all_search_y0)\n",
    "                        IQR_y0 = np.quantile(all_search_y0, 0.75) - np.quantile(all_search_y0, 0.25)\n",
    "                        all_search_y0 = [y for y in all_search_y0 if (y>=median_y0-(1.5*IQR_y0)) and (y<=median_y0+(1.5*IQR_y0))]\n",
    "                        min_search_y0 = min(all_search_y0)\n",
    "                        max_search_y0 = max(all_search_y0)\n",
    "\n",
    "                        search_x0 = min_search_x0\n",
    "                        search_y0 = min_search_y0\n",
    "                        search_w = (max_search_x0-min_search_x0) + int(ref_bbox[2]+(2*search_margin))\n",
    "                        search_h = (max_search_y0-min_search_y0) + int(previous_bbox[3]+(2*search_margin))\n",
    "                        search_bbox = (search_x0, search_y0, search_w, search_h)\n",
    "                        search_region = full_frame[search_y0:search_y0+search_h,\n",
    "                                                      search_x0:search_x0+search_w]    \n",
    "\n",
    "                    mean_corr, max_loc = compute_similarity_map(search_region, ref_patches, ref_idx)\n",
    "                    corr_with_ref[frame] = mean_corr\n",
    "                    \n",
    "                    if mean_corr >= threshold:\n",
    "                        valid = True\n",
    "                        current_w = ref_bbox[2]\n",
    "                        current_h = ref_bbox[3]\n",
    "                        current_x0 = search_x0 + max_loc[0]\n",
    "                        current_y0 = search_y0 + max_loc[1]\n",
    "                        current_bbox = (current_x0, current_y0, current_w, current_h)\n",
    "\n",
    "                        img_bbox = cv2.rectangle(cv2.cvtColor(full_frame, cv2.COLOR_GRAY2BGR),\n",
    "                                                     (search_x0, search_y0),\n",
    "                                                     (search_x0+search_w, search_y0+search_h),\n",
    "                                                     (255, 255, 255), 2)\n",
    "                        img_bbox = cv2.rectangle(img_bbox,\n",
    "                                                     (current_bbox[0], current_bbox[1]),\n",
    "                                                     (current_bbox[0] + current_bbox[2], current_bbox[1] + current_bbox[3]),\n",
    "                                                     (0, 255, 0), 2)\n",
    "                        img_bbox = cv2.putText(img_bbox, 'frame: '+str(frame), (25,25), cv2.FONT_HERSHEY_SIMPLEX,  \n",
    "                                       1, (0,255,0), 2, cv2.LINE_AA) \n",
    "                        img_bbox = cv2.putText(img_bbox, 'corr: '+str(mean_corr), (25,50), cv2.FONT_HERSHEY_SIMPLEX,  \n",
    "                                       1, (0,255,0), 2, cv2.LINE_AA) \n",
    "\n",
    "                        out_array[frame] = img_bbox\n",
    "\n",
    "                        all_lesion_bboxes[frame] = current_bbox[:]\n",
    "                        previous_bbox = current_bbox[:]\n",
    "                        \n",
    "                    else:\n",
    "                        valid = False\n",
    "                        img_bbox = cv2.rectangle(cv2.cvtColor(full_frame, cv2.COLOR_GRAY2BGR),\n",
    "                                                     (search_x0, search_y0),\n",
    "                                                     (search_x0+search_w, search_y0+search_h),\n",
    "                                                     (0, 0, 255), 2)\n",
    "                        img_bbox = cv2.putText(img_bbox, 'frame: '+str(frame), (25,25), cv2.FONT_HERSHEY_SIMPLEX,  \n",
    "                                       1, (0,0,255), 2, cv2.LINE_AA) \n",
    "                        img_bbox = cv2.putText(img_bbox, 'corr: '+str(mean_corr), (25,50), cv2.FONT_HERSHEY_SIMPLEX,  \n",
    "                                       1, (0,0,255), 2, cv2.LINE_AA) \n",
    "\n",
    "                        out_array[frame] = img_bbox\n",
    "            ##############################################################\n",
    "            \n",
    "            #backward tracking\n",
    "            ##############################################################\n",
    "            if ref_frame > ref_begin:  \n",
    "                previous_bbox = ref_bbox\n",
    "                valid = True\n",
    "\n",
    "                for frame in range(ref_frame-1, ref_begin-1, -step):\n",
    "\n",
    "                    full_frame = full_array[frame]\n",
    "\n",
    "                    if valid:\n",
    "                        search_w = int(previous_bbox[2]+(2*search_margin))\n",
    "                        search_h = int(previous_bbox[3]+(2*search_margin))\n",
    "                        search_x0 = int(previous_bbox[0] - ((search_w - previous_bbox[2])/2))\n",
    "                        search_y0 = int(previous_bbox[1] - ((search_h - previous_bbox[3])/2))\n",
    "                        search_bbox = (search_x0, search_y0, search_w, search_h)\n",
    "                        search_region = full_frame[search_y0:search_y0+search_h,\n",
    "                                                  search_x0:search_x0+search_w]\n",
    "\n",
    "                        all_search_bboxes[frame] = search_bbox\n",
    "\n",
    "                    else:\n",
    "                        all_search_x0 = [b[0] for b in all_search_bboxes[ref_begin:ref_frame] if not(b is None)]\n",
    "                        median_x0 = np.median(all_search_x0)\n",
    "                        IQR_x0 = np.quantile(all_search_x0, 0.75) - np.quantile(all_search_x0, 0.25)\n",
    "                        all_search_x0 = [x for x in all_search_x0 if (x>=median_x0-(1.5*IQR_x0)) and (x<=median_x0+(1.5*IQR_x0))]\n",
    "                        min_search_x0 = min(all_search_x0)\n",
    "                        max_search_x0 = max(all_search_x0)\n",
    "\n",
    "                        all_search_y0 = [b[1] for b in all_search_bboxes[ref_begin:ref_frame] if not(b is None)]\n",
    "                        median_y0 = np.median(all_search_y0)\n",
    "                        IQR_y0 = np.quantile(all_search_y0, 0.75) - np.quantile(all_search_y0, 0.25)\n",
    "                        all_search_y0 = [y for y in all_search_y0 if (y>=median_y0-(1.5*IQR_y0)) and (y<=median_y0+(1.5*IQR_y0))]\n",
    "                        min_search_y0 = min(all_search_y0)\n",
    "                        max_search_y0 = max(all_search_y0)\n",
    "\n",
    "                        search_x0 = min_search_x0\n",
    "                        search_y0 = min_search_y0\n",
    "                        search_w = (max_search_x0-min_search_x0) + int(ref_bbox[2]+(2*search_margin))\n",
    "                        search_h = (max_search_y0-min_search_y0) + int(previous_bbox[3]+(2*search_margin))\n",
    "                        search_bbox = (search_x0, search_y0, search_w, search_h)\n",
    "                        search_region = full_frame[search_y0:search_y0+search_h,\n",
    "                                                      search_x0:search_x0+search_w]    \n",
    "\n",
    "                    mean_corr, max_loc = compute_similarity_map(search_region, ref_patches, ref_idx)\n",
    "                    corr_with_ref[frame] = mean_corr\n",
    "                    \n",
    "                    if mean_corr >= threshold:\n",
    "                        valid = True\n",
    "                        current_w = ref_bbox[2]\n",
    "                        current_h = ref_bbox[3]\n",
    "                        current_x0 = search_x0 + max_loc[0]\n",
    "                        current_y0 = search_y0 + max_loc[1]\n",
    "                        current_bbox = (current_x0, current_y0, current_w, current_h)\n",
    "\n",
    "                        img_bbox = cv2.rectangle(cv2.cvtColor(full_frame, cv2.COLOR_GRAY2BGR),\n",
    "                                                     (search_x0, search_y0),\n",
    "                                                     (search_x0+search_w, search_y0+search_h),\n",
    "                                                     (255, 255, 255), 2)\n",
    "                        img_bbox = cv2.rectangle(img_bbox,\n",
    "                                                     (current_bbox[0], current_bbox[1]),\n",
    "                                                     (current_bbox[0] + current_bbox[2], current_bbox[1] + current_bbox[3]),\n",
    "                                                     (0, 255, 0), 2)\n",
    "                        img_bbox = cv2.putText(img_bbox, 'frame: '+str(frame), (25,25), cv2.FONT_HERSHEY_SIMPLEX,  \n",
    "                                       1, (0,255,0), 2, cv2.LINE_AA) \n",
    "                        img_bbox = cv2.putText(img_bbox, 'corr: '+str(mean_corr), (25,50), cv2.FONT_HERSHEY_SIMPLEX,  \n",
    "                                       1, (0,255,0), 2, cv2.LINE_AA) \n",
    "\n",
    "                        out_array[frame] = img_bbox\n",
    "\n",
    "                        all_lesion_bboxes[frame] = current_bbox[:]\n",
    "                        previous_bbox = current_bbox[:]\n",
    "                        \n",
    "                    else:\n",
    "                        valid = False\n",
    "                        img_bbox = cv2.rectangle(cv2.cvtColor(full_frame, cv2.COLOR_GRAY2BGR),\n",
    "                                                     (search_x0, search_y0),\n",
    "                                                     (search_x0+search_w, search_y0+search_h),\n",
    "                                                     (0, 0, 255), 2)\n",
    "                        img_bbox = cv2.putText(img_bbox, 'frame: '+str(frame), (25,25), cv2.FONT_HERSHEY_SIMPLEX,  \n",
    "                                       1, (0,0,255), 2, cv2.LINE_AA) \n",
    "                        img_bbox = cv2.putText(img_bbox, 'corr: '+str(mean_corr), (25,50), cv2.FONT_HERSHEY_SIMPLEX,  \n",
    "                                       1, (0,0,255), 2, cv2.LINE_AA) \n",
    "\n",
    "                        out_array[frame] = img_bbox\n",
    "            ##############################################################\n",
    "            \n",
    "\n",
    "        #check if lesion bbox in any frame move in this iteration\n",
    "        #####################\n",
    "        bbox_move = check_bbox_move(previous_all_lesion_bboxes, all_lesion_bboxes)\n",
    "        if bbox_move or (threshold < min([e for e in corr_with_ref if not(e is None)])):\n",
    "            break\n",
    "        #####################\n",
    "\n",
    "        previous_threshold = threshold\n",
    "        previous_all_lesion_bboxes = all_lesion_bboxes[:]\n",
    "        previous_out_array = out_array.copy()\n",
    "        previous_corr_with_ref = corr_with_ref.copy()\n",
    "        threshold -= threshold_decrease_per_step\n",
    "        iteration += 1\n",
    "     \n",
    "    print('iteration:', iteration-1)\n",
    "    print('threshold:', previous_threshold)\n",
    "\n",
    "    out_array = previous_out_array.copy()\n",
    "   \n",
    "    export_video(out_array, mp4_path, CineRate=10)\n",
    "    \n",
    "    return full_array, previous_all_lesion_bboxes, ref_frames, bboxes, masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 12)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P_001\n",
      "../sample-data/P_001/pickle_bmode_CE_gray/ceus_inj1_wi_000000.000000.pkl\n",
      "(753, 802, 1442)\n",
      "(753, 802, 1442)\n",
      "initial threshold: 1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1\n",
      "threshold: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x44495658/'XVID' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usable bboxes: 322\n",
      "outlier bboxes: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:17<00:00, 17.46s/it]\n"
     ]
    }
   ],
   "source": [
    "for ROI_margin_suffix in ROI_margin_suffix_list:\n",
    "    for frame_rate_suffix in frame_rate_suffix_list:\n",
    "        \n",
    "        export_dir = export_dir_prefix + ROI_margin_suffix + '_' + frame_rate_suffix\n",
    "        \n",
    "        df = pd.read_excel(dataset_path, dtype=str)\n",
    "        print(df.shape)\n",
    "        \n",
    "        for col in df.columns:\n",
    "            if col.endswith('_path'):\n",
    "                df.loc[:,col] = df[col].apply(add_data_dir, args=(data_dir,))\n",
    "                \n",
    "        for row_idx in tqdm(df.index):\n",
    "            patient_code_inj = df.loc[row_idx, 'patient_code_inj']\n",
    "            print(patient_code_inj)\n",
    "            pickle_full_path = df.loc[row_idx, 'pickle_bmode_CE_gray_path']\n",
    "            print(pickle_full_path)\n",
    "            mp4_path = join(export_mp4_dir, patient_code_inj+'.mp4')\n",
    "            nifti_segmentation_path = df.loc[row_idx, 'nifti_segmentation_path']\n",
    "\n",
    "            full_array, bmode_MC_bboxes, ref_frames, ref_bboxes, ref_masks = perform_MC(pickle_full_path, \n",
    "                                                                                        nifti_segmentation_path, \n",
    "                                                                                        mp4_path,\n",
    "                                                                                        ROI_margin_suffix, \n",
    "                                                                                        frame_rate_suffix)\n",
    "\n",
    "            #resize all MC bboxes to the same size\n",
    "            bmode_MC_bboxes = resize_MC_bboxes(bmode_MC_bboxes)\n",
    "\n",
    "            #remove outlier bboxes\n",
    "            bmode_MC_bboxes = remove_outlier_bboxes(bmode_MC_bboxes, full_array)\n",
    "\n",
    "            n_frames = full_array.shape[0]\n",
    "\n",
    "            x0_bmode = int(df.loc[row_idx, 'x0_bmode'])\n",
    "            y0_bmode = int(df.loc[row_idx, 'y0_bmode'])\n",
    "            w_bmode = int(df.loc[row_idx, 'w_bmode'])\n",
    "            h_bmode = int(df.loc[row_idx, 'h_bmode'])\n",
    "            x0_CE = int(df.loc[row_idx, 'x0_CE'])\n",
    "            y0_CE = int(df.loc[row_idx, 'y0_CE'])\n",
    "            w_CE = int(df.loc[row_idx, 'w_CE'])\n",
    "            h_CE = int(df.loc[row_idx, 'h_CE'])\n",
    "            CE_side = df.loc[row_idx, 'CE_window_left(l)_or_right(r)']\n",
    "\n",
    "            CE_MC_bboxes = create_CE_MC_bboxes(bmode_MC_bboxes, x0_bmode, x0_CE, CE_side)\n",
    "            bmode_ori_bboxes = create_ori_bboxes(ref_frames, ref_bboxes, n_frames).astype('int')\n",
    "            CE_ori_bboxes = create_CE_ori_bboxes(bmode_ori_bboxes, x0_bmode, x0_CE, CE_side).astype('int')\n",
    "\n",
    "            #cut ROI\n",
    "            if not fixed_size_ROI:\n",
    "                #use \"cut_ROI\" function to get ROI exactly fit to the lesion\n",
    "                bmode_MC_ROI = cut_ROI(full_array, bmode_MC_bboxes)\n",
    "                CE_MC_ROI = cut_ROI(full_array, CE_MC_bboxes)\n",
    "            else:\n",
    "                #use \"cut_ROI200\" function to get a fixed size ROI\n",
    "                bmode_MC_ROI = cut_ROI200(full_array, bmode_MC_bboxes, (x0_bmode,y0_bmode,w_bmode,h_bmode))\n",
    "                CE_MC_ROI = cut_ROI200(full_array, CE_MC_bboxes, (x0_CE,y0_CE,w_CE,h_CE))\n",
    "\n",
    "            export_pickle(bmode_MC_ROI, join(export_dir, patient_code_inj, 'bmode_MC_ROI.pkl'))\n",
    "            export_pickle(CE_MC_ROI, join(export_dir, patient_code_inj, 'CE_MC_ROI.pkl'))\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-11.m91",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-11:m91"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
